{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dictionaries\n",
    "1. Create a dictionary with two keys: `even_numbers` and `odd_numbers`. The first key should have all the even numbers in this range `[0, 2000]`, and the second key must have all the odd numbers in this range `[9000, 19000]`. The values should be stored in a `list`. **Hint: Use the `np.arange`, `zip`, and `np.tolist()` functions.** <br><br>\n",
    "2. Print the value of `brand` key of `car` dictionary. **Hint: Use the `get` method.** <br><br>\n",
    "3. Print all the the values of `brand` key of `car` dictionary. **Hint: Use the `values` method.** <br><br>\n",
    "4. Print the max value  of `friday` in `january` of `hr_sleep` dictionary. **Hint: [Indexing in nested dictioanries](https://stackoverflow.com/questions/25836376/how-to-get-the-inner-indexes-of-a-nested-dictionary-in-python).** <br><br>\n",
    "5. Add `march` key to the `hr_sleep` dictionary using `week1` and `values2` Python lists. **Hint: Use `zip` function adn [this link](https://stackoverflow.com/questions/1024847/how-can-i-add-new-keys-to-a-dictionary).** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "\n",
    "hr_sleep = {\"january\": {\"wednesday\": 7,\n",
    "                      \"thursday\": 8,\n",
    "                      \"friday\": [2, 2, 1, 2]},\n",
    "          \"february\": {\"saturday\": 5,\n",
    "                       \"sunday\": 10,\n",
    "                       \"monday\": 8\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = ['monday', 'sunday']\n",
    "values2 = [ [2, 3, 4 ] , 8, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a dictionary with two keys: `even_numbers` and `odd_numbers`. The first key should have all the even numbers in this range `[0, 2000]`, and the second key must have all the odd numbers in this range `[9000, 19000]`. The values should be stored in a `list`. **Hint: Use the `np.arange`, `zip`, and `np.tolist()` functions.** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 9001, 2: 9003, 4: 9005, 6: 9007, 8: 9009, 10: 9011, 12: 9013, 14: 9015, 16: 9017, 18: 9019, 20: 9021, 22: 9023, 24: 9025, 26: 9027, 28: 9029, 30: 9031, 32: 9033, 34: 9035, 36: 9037, 38: 9039, 40: 9041, 42: 9043, 44: 9045, 46: 9047, 48: 9049, 50: 9051, 52: 9053, 54: 9055, 56: 9057, 58: 9059, 60: 9061, 62: 9063, 64: 9065, 66: 9067, 68: 9069, 70: 9071, 72: 9073, 74: 9075, 76: 9077, 78: 9079, 80: 9081, 82: 9083, 84: 9085, 86: 9087, 88: 9089, 90: 9091, 92: 9093, 94: 9095, 96: 9097, 98: 9099, 100: 9101, 102: 9103, 104: 9105, 106: 9107, 108: 9109, 110: 9111, 112: 9113, 114: 9115, 116: 9117, 118: 9119, 120: 9121, 122: 9123, 124: 9125, 126: 9127, 128: 9129, 130: 9131, 132: 9133, 134: 9135, 136: 9137, 138: 9139, 140: 9141, 142: 9143, 144: 9145, 146: 9147, 148: 9149, 150: 9151, 152: 9153, 154: 9155, 156: 9157, 158: 9159, 160: 9161, 162: 9163, 164: 9165, 166: 9167, 168: 9169, 170: 9171, 172: 9173, 174: 9175, 176: 9177, 178: 9179, 180: 9181, 182: 9183, 184: 9185, 186: 9187, 188: 9189, 190: 9191, 192: 9193, 194: 9195, 196: 9197, 198: 9199, 200: 9201, 202: 9203, 204: 9205, 206: 9207, 208: 9209, 210: 9211, 212: 9213, 214: 9215, 216: 9217, 218: 9219, 220: 9221, 222: 9223, 224: 9225, 226: 9227, 228: 9229, 230: 9231, 232: 9233, 234: 9235, 236: 9237, 238: 9239, 240: 9241, 242: 9243, 244: 9245, 246: 9247, 248: 9249, 250: 9251, 252: 9253, 254: 9255, 256: 9257, 258: 9259, 260: 9261, 262: 9263, 264: 9265, 266: 9267, 268: 9269, 270: 9271, 272: 9273, 274: 9275, 276: 9277, 278: 9279, 280: 9281, 282: 9283, 284: 9285, 286: 9287, 288: 9289, 290: 9291, 292: 9293, 294: 9295, 296: 9297, 298: 9299, 300: 9301, 302: 9303, 304: 9305, 306: 9307, 308: 9309, 310: 9311, 312: 9313, 314: 9315, 316: 9317, 318: 9319, 320: 9321, 322: 9323, 324: 9325, 326: 9327, 328: 9329, 330: 9331, 332: 9333, 334: 9335, 336: 9337, 338: 9339, 340: 9341, 342: 9343, 344: 9345, 346: 9347, 348: 9349, 350: 9351, 352: 9353, 354: 9355, 356: 9357, 358: 9359, 360: 9361, 362: 9363, 364: 9365, 366: 9367, 368: 9369, 370: 9371, 372: 9373, 374: 9375, 376: 9377, 378: 9379, 380: 9381, 382: 9383, 384: 9385, 386: 9387, 388: 9389, 390: 9391, 392: 9393, 394: 9395, 396: 9397, 398: 9399, 400: 9401, 402: 9403, 404: 9405, 406: 9407, 408: 9409, 410: 9411, 412: 9413, 414: 9415, 416: 9417, 418: 9419, 420: 9421, 422: 9423, 424: 9425, 426: 9427, 428: 9429, 430: 9431, 432: 9433, 434: 9435, 436: 9437, 438: 9439, 440: 9441, 442: 9443, 444: 9445, 446: 9447, 448: 9449, 450: 9451, 452: 9453, 454: 9455, 456: 9457, 458: 9459, 460: 9461, 462: 9463, 464: 9465, 466: 9467, 468: 9469, 470: 9471, 472: 9473, 474: 9475, 476: 9477, 478: 9479, 480: 9481, 482: 9483, 484: 9485, 486: 9487, 488: 9489, 490: 9491, 492: 9493, 494: 9495, 496: 9497, 498: 9499, 500: 9501, 502: 9503, 504: 9505, 506: 9507, 508: 9509, 510: 9511, 512: 9513, 514: 9515, 516: 9517, 518: 9519, 520: 9521, 522: 9523, 524: 9525, 526: 9527, 528: 9529, 530: 9531, 532: 9533, 534: 9535, 536: 9537, 538: 9539, 540: 9541, 542: 9543, 544: 9545, 546: 9547, 548: 9549, 550: 9551, 552: 9553, 554: 9555, 556: 9557, 558: 9559, 560: 9561, 562: 9563, 564: 9565, 566: 9567, 568: 9569, 570: 9571, 572: 9573, 574: 9575, 576: 9577, 578: 9579, 580: 9581, 582: 9583, 584: 9585, 586: 9587, 588: 9589, 590: 9591, 592: 9593, 594: 9595, 596: 9597, 598: 9599, 600: 9601, 602: 9603, 604: 9605, 606: 9607, 608: 9609, 610: 9611, 612: 9613, 614: 9615, 616: 9617, 618: 9619, 620: 9621, 622: 9623, 624: 9625, 626: 9627, 628: 9629, 630: 9631, 632: 9633, 634: 9635, 636: 9637, 638: 9639, 640: 9641, 642: 9643, 644: 9645, 646: 9647, 648: 9649, 650: 9651, 652: 9653, 654: 9655, 656: 9657, 658: 9659, 660: 9661, 662: 9663, 664: 9665, 666: 9667, 668: 9669, 670: 9671, 672: 9673, 674: 9675, 676: 9677, 678: 9679, 680: 9681, 682: 9683, 684: 9685, 686: 9687, 688: 9689, 690: 9691, 692: 9693, 694: 9695, 696: 9697, 698: 9699, 700: 9701, 702: 9703, 704: 9705, 706: 9707, 708: 9709, 710: 9711, 712: 9713, 714: 9715, 716: 9717, 718: 9719, 720: 9721, 722: 9723, 724: 9725, 726: 9727, 728: 9729, 730: 9731, 732: 9733, 734: 9735, 736: 9737, 738: 9739, 740: 9741, 742: 9743, 744: 9745, 746: 9747, 748: 9749, 750: 9751, 752: 9753, 754: 9755, 756: 9757, 758: 9759, 760: 9761, 762: 9763, 764: 9765, 766: 9767, 768: 9769, 770: 9771, 772: 9773, 774: 9775, 776: 9777, 778: 9779, 780: 9781, 782: 9783, 784: 9785, 786: 9787, 788: 9789, 790: 9791, 792: 9793, 794: 9795, 796: 9797, 798: 9799, 800: 9801, 802: 9803, 804: 9805, 806: 9807, 808: 9809, 810: 9811, 812: 9813, 814: 9815, 816: 9817, 818: 9819, 820: 9821, 822: 9823, 824: 9825, 826: 9827, 828: 9829, 830: 9831, 832: 9833, 834: 9835, 836: 9837, 838: 9839, 840: 9841, 842: 9843, 844: 9845, 846: 9847, 848: 9849, 850: 9851, 852: 9853, 854: 9855, 856: 9857, 858: 9859, 860: 9861, 862: 9863, 864: 9865, 866: 9867, 868: 9869, 870: 9871, 872: 9873, 874: 9875, 876: 9877, 878: 9879, 880: 9881, 882: 9883, 884: 9885, 886: 9887, 888: 9889, 890: 9891, 892: 9893, 894: 9895, 896: 9897, 898: 9899, 900: 9901, 902: 9903, 904: 9905, 906: 9907, 908: 9909, 910: 9911, 912: 9913, 914: 9915, 916: 9917, 918: 9919, 920: 9921, 922: 9923, 924: 9925, 926: 9927, 928: 9929, 930: 9931, 932: 9933, 934: 9935, 936: 9937, 938: 9939, 940: 9941, 942: 9943, 944: 9945, 946: 9947, 948: 9949, 950: 9951, 952: 9953, 954: 9955, 956: 9957, 958: 9959, 960: 9961, 962: 9963, 964: 9965, 966: 9967, 968: 9969, 970: 9971, 972: 9973, 974: 9975, 976: 9977, 978: 9979, 980: 9981, 982: 9983, 984: 9985, 986: 9987, 988: 9989, 990: 9991, 992: 9993, 994: 9995, 996: 9997, 998: 9999, 1000: 10001, 1002: 10003, 1004: 10005, 1006: 10007, 1008: 10009, 1010: 10011, 1012: 10013, 1014: 10015, 1016: 10017, 1018: 10019, 1020: 10021, 1022: 10023, 1024: 10025, 1026: 10027, 1028: 10029, 1030: 10031, 1032: 10033, 1034: 10035, 1036: 10037, 1038: 10039, 1040: 10041, 1042: 10043, 1044: 10045, 1046: 10047, 1048: 10049, 1050: 10051, 1052: 10053, 1054: 10055, 1056: 10057, 1058: 10059, 1060: 10061, 1062: 10063, 1064: 10065, 1066: 10067, 1068: 10069, 1070: 10071, 1072: 10073, 1074: 10075, 1076: 10077, 1078: 10079, 1080: 10081, 1082: 10083, 1084: 10085, 1086: 10087, 1088: 10089, 1090: 10091, 1092: 10093, 1094: 10095, 1096: 10097, 1098: 10099, 1100: 10101, 1102: 10103, 1104: 10105, 1106: 10107, 1108: 10109, 1110: 10111, 1112: 10113, 1114: 10115, 1116: 10117, 1118: 10119, 1120: 10121, 1122: 10123, 1124: 10125, 1126: 10127, 1128: 10129, 1130: 10131, 1132: 10133, 1134: 10135, 1136: 10137, 1138: 10139, 1140: 10141, 1142: 10143, 1144: 10145, 1146: 10147, 1148: 10149, 1150: 10151, 1152: 10153, 1154: 10155, 1156: 10157, 1158: 10159, 1160: 10161, 1162: 10163, 1164: 10165, 1166: 10167, 1168: 10169, 1170: 10171, 1172: 10173, 1174: 10175, 1176: 10177, 1178: 10179, 1180: 10181, 1182: 10183, 1184: 10185, 1186: 10187, 1188: 10189, 1190: 10191, 1192: 10193, 1194: 10195, 1196: 10197, 1198: 10199, 1200: 10201, 1202: 10203, 1204: 10205, 1206: 10207, 1208: 10209, 1210: 10211, 1212: 10213, 1214: 10215, 1216: 10217, 1218: 10219, 1220: 10221, 1222: 10223, 1224: 10225, 1226: 10227, 1228: 10229, 1230: 10231, 1232: 10233, 1234: 10235, 1236: 10237, 1238: 10239, 1240: 10241, 1242: 10243, 1244: 10245, 1246: 10247, 1248: 10249, 1250: 10251, 1252: 10253, 1254: 10255, 1256: 10257, 1258: 10259, 1260: 10261, 1262: 10263, 1264: 10265, 1266: 10267, 1268: 10269, 1270: 10271, 1272: 10273, 1274: 10275, 1276: 10277, 1278: 10279, 1280: 10281, 1282: 10283, 1284: 10285, 1286: 10287, 1288: 10289, 1290: 10291, 1292: 10293, 1294: 10295, 1296: 10297, 1298: 10299, 1300: 10301, 1302: 10303, 1304: 10305, 1306: 10307, 1308: 10309, 1310: 10311, 1312: 10313, 1314: 10315, 1316: 10317, 1318: 10319, 1320: 10321, 1322: 10323, 1324: 10325, 1326: 10327, 1328: 10329, 1330: 10331, 1332: 10333, 1334: 10335, 1336: 10337, 1338: 10339, 1340: 10341, 1342: 10343, 1344: 10345, 1346: 10347, 1348: 10349, 1350: 10351, 1352: 10353, 1354: 10355, 1356: 10357, 1358: 10359, 1360: 10361, 1362: 10363, 1364: 10365, 1366: 10367, 1368: 10369, 1370: 10371, 1372: 10373, 1374: 10375, 1376: 10377, 1378: 10379, 1380: 10381, 1382: 10383, 1384: 10385, 1386: 10387, 1388: 10389, 1390: 10391, 1392: 10393, 1394: 10395, 1396: 10397, 1398: 10399, 1400: 10401, 1402: 10403, 1404: 10405, 1406: 10407, 1408: 10409, 1410: 10411, 1412: 10413, 1414: 10415, 1416: 10417, 1418: 10419, 1420: 10421, 1422: 10423, 1424: 10425, 1426: 10427, 1428: 10429, 1430: 10431, 1432: 10433, 1434: 10435, 1436: 10437, 1438: 10439, 1440: 10441, 1442: 10443, 1444: 10445, 1446: 10447, 1448: 10449, 1450: 10451, 1452: 10453, 1454: 10455, 1456: 10457, 1458: 10459, 1460: 10461, 1462: 10463, 1464: 10465, 1466: 10467, 1468: 10469, 1470: 10471, 1472: 10473, 1474: 10475, 1476: 10477, 1478: 10479, 1480: 10481, 1482: 10483, 1484: 10485, 1486: 10487, 1488: 10489, 1490: 10491, 1492: 10493, 1494: 10495, 1496: 10497, 1498: 10499, 1500: 10501, 1502: 10503, 1504: 10505, 1506: 10507, 1508: 10509, 1510: 10511, 1512: 10513, 1514: 10515, 1516: 10517, 1518: 10519, 1520: 10521, 1522: 10523, 1524: 10525, 1526: 10527, 1528: 10529, 1530: 10531, 1532: 10533, 1534: 10535, 1536: 10537, 1538: 10539, 1540: 10541, 1542: 10543, 1544: 10545, 1546: 10547, 1548: 10549, 1550: 10551, 1552: 10553, 1554: 10555, 1556: 10557, 1558: 10559, 1560: 10561, 1562: 10563, 1564: 10565, 1566: 10567, 1568: 10569, 1570: 10571, 1572: 10573, 1574: 10575, 1576: 10577, 1578: 10579, 1580: 10581, 1582: 10583, 1584: 10585, 1586: 10587, 1588: 10589, 1590: 10591, 1592: 10593, 1594: 10595, 1596: 10597, 1598: 10599, 1600: 10601, 1602: 10603, 1604: 10605, 1606: 10607, 1608: 10609, 1610: 10611, 1612: 10613, 1614: 10615, 1616: 10617, 1618: 10619, 1620: 10621, 1622: 10623, 1624: 10625, 1626: 10627, 1628: 10629, 1630: 10631, 1632: 10633, 1634: 10635, 1636: 10637, 1638: 10639, 1640: 10641, 1642: 10643, 1644: 10645, 1646: 10647, 1648: 10649, 1650: 10651, 1652: 10653, 1654: 10655, 1656: 10657, 1658: 10659, 1660: 10661, 1662: 10663, 1664: 10665, 1666: 10667, 1668: 10669, 1670: 10671, 1672: 10673, 1674: 10675, 1676: 10677, 1678: 10679, 1680: 10681, 1682: 10683, 1684: 10685, 1686: 10687, 1688: 10689, 1690: 10691, 1692: 10693, 1694: 10695, 1696: 10697, 1698: 10699, 1700: 10701, 1702: 10703, 1704: 10705, 1706: 10707, 1708: 10709, 1710: 10711, 1712: 10713, 1714: 10715, 1716: 10717, 1718: 10719, 1720: 10721, 1722: 10723, 1724: 10725, 1726: 10727, 1728: 10729, 1730: 10731, 1732: 10733, 1734: 10735, 1736: 10737, 1738: 10739, 1740: 10741, 1742: 10743, 1744: 10745, 1746: 10747, 1748: 10749, 1750: 10751, 1752: 10753, 1754: 10755, 1756: 10757, 1758: 10759, 1760: 10761, 1762: 10763, 1764: 10765, 1766: 10767, 1768: 10769, 1770: 10771, 1772: 10773, 1774: 10775, 1776: 10777, 1778: 10779, 1780: 10781, 1782: 10783, 1784: 10785, 1786: 10787, 1788: 10789, 1790: 10791, 1792: 10793, 1794: 10795, 1796: 10797, 1798: 10799, 1800: 10801, 1802: 10803, 1804: 10805, 1806: 10807, 1808: 10809, 1810: 10811, 1812: 10813, 1814: 10815, 1816: 10817, 1818: 10819, 1820: 10821, 1822: 10823, 1824: 10825, 1826: 10827, 1828: 10829, 1830: 10831, 1832: 10833, 1834: 10835, 1836: 10837, 1838: 10839, 1840: 10841, 1842: 10843, 1844: 10845, 1846: 10847, 1848: 10849, 1850: 10851, 1852: 10853, 1854: 10855, 1856: 10857, 1858: 10859, 1860: 10861, 1862: 10863, 1864: 10865, 1866: 10867, 1868: 10869, 1870: 10871, 1872: 10873, 1874: 10875, 1876: 10877, 1878: 10879, 1880: 10881, 1882: 10883, 1884: 10885, 1886: 10887, 1888: 10889, 1890: 10891, 1892: 10893, 1894: 10895, 1896: 10897, 1898: 10899, 1900: 10901, 1902: 10903, 1904: 10905, 1906: 10907, 1908: 10909, 1910: 10911, 1912: 10913, 1914: 10915, 1916: 10917, 1918: 10919, 1920: 10921, 1922: 10923, 1924: 10925, 1926: 10927, 1928: 10929, 1930: 10931, 1932: 10933, 1934: 10935, 1936: 10937, 1938: 10939, 1940: 10941, 1942: 10943, 1944: 10945, 1946: 10947, 1948: 10949, 1950: 10951, 1952: 10953, 1954: 10955, 1956: 10957, 1958: 10959, 1960: 10961, 1962: 10963, 1964: 10965, 1966: 10967, 1968: 10969, 1970: 10971, 1972: 10973, 1974: 10975, 1976: 10977, 1978: 10979, 1980: 10981, 1982: 10983, 1984: 10985, 1986: 10987, 1988: 10989, 1990: 10991, 1992: 10993, 1994: 10995, 1996: 10997, 1998: 10999, 2000: 11001}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Importing numpy as np \n",
    "\n",
    "#Creating the arrays requiered with the np.arange function. \n",
    "even_numbers=np.arange(0,2002,2)\n",
    "#print(even_numbers)\n",
    "\n",
    "odd_numbers=np.arange(9001,19000,2)\n",
    "#print(odd_numbers)\n",
    "\n",
    "\n",
    "#Converting the arrays in lists with the np.tolist() function.\n",
    "list_even=even_numbers.tolist()\n",
    "#print(list_even)\n",
    "\n",
    "list_odd=odd_numbers.tolist()\n",
    "#print(list_odd)\n",
    "\n",
    "#Converting the list in a dictionary.\n",
    "dict1= dict( zip( list_even, list_odd))\n",
    "print(dict1)\n",
    "#type(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Print the value of `brand` key of `car` dictionary. **Hint: Use the `get` method.** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ford'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.get('brand') #Using the get method in order to obtain the value of \"brand\" key of car dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Print all the the values of `brand` key of `car` dictionary. **Hint: Use the `values` method.** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Ford', 'Mustang', 1964])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car.values() #Using the values method in order to obtain all the values of the car dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Print the max value  of `friday` in `january` of `hr_sleep` dictionary. **Hint: [Indexing in nested dictioanries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Using the get function in order to obtain the values, first of the month:january amd then to get the day: friday\n",
    "#The result is in the object: friday_items\n",
    "friday_items=hr_sleep.get('january').get('friday')\n",
    "\n",
    "#we have \"friday_items\" the represents \"friday\" in \"january\" of hr_sleep dictionary.\n",
    "#Using the max function in order to obtain the max value.\n",
    "max_value=max(friday_items)  \n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Add march key to the hr_sleep dictionary using week1 and values2 Python lists. Hint: Use zip function adn this link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_sleep = {\"january\": {\"wednesday\": 7,\n",
    "                      \"thursday\": 8,\n",
    "                      \"friday\": [2, 2, 1, 2]},\n",
    "          \"february\": {\"saturday\": 5,\n",
    "                       \"sunday\": 10,\n",
    "                       \"monday\": 8\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'january': {'wednesday': 7, 'thursday': 8, 'friday': [2, 2, 1, 2]}, 'february': {'saturday': 5, 'sunday': 10, 'monday': 8}}\n"
     ]
    }
   ],
   "source": [
    "print (hr_sleep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['monday', 'sunday']\n",
      "[[2, 3, 4], 8]\n"
     ]
    }
   ],
   "source": [
    "week1 = ['monday', 'sunday']\n",
    "values2 = [ [2, 3, 4 ] , 8, ]\n",
    "print (week1)\n",
    "print (values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'monday': [2, 3, 4], 'sunday': 8}\n"
     ]
    }
   ],
   "source": [
    "march = dict( zip( week1, values2))\n",
    "print(march)  #Zip function is used to pair together one the first items in each iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'march': {'monday': [2, 3, 4], 'sunday': 8}}\n"
     ]
    }
   ],
   "source": [
    "march2 = {} #Create a new empty dictionary\n",
    "march2 [\"march\"] = march #This dictionary is named march 2 and contains item \"march\" and key created above. \n",
    "print (march2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'january': {'wednesday': 7, 'thursday': 8, 'friday': [2, 2, 1, 2]}, 'february': {'saturday': 5, 'sunday': 10, 'monday': 8}, 'monday': [2, 3, 4], 'sunday': 8}\n"
     ]
    }
   ],
   "source": [
    "hr_sleep.update (march)  #Use update to aggregate a new key on existing dictionary\n",
    "print (hr_sleep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Numpy\n",
    "1. Replace all the `even_numbers` in `np1` with 100. **Hint: Use `indexing` in arrys and [this filer](https://stackoverflow.com/questions/41638751/filtering-even-numbers-in-python).** <br><br>\n",
    "2. Create a 3x3 matrix with values ranging from 0 to 8. **Hint: Use `np.arange` and `np.reshape` method.** <br><br>\n",
    "3. Consider an array `Z = [1,2,3,4,5,6,7,8,9,10]`, generate an array `R = [ [ 1, 2, 3, 4], [ 2, 3, 4, 5 ], [ 3, 4, 5, 6 ], ..., [ 7, 8, 9, 10 ] ]`?.**Hint: Use `np.arange` and `np.concatenate`** <br><br>\n",
    "4. Create a 3x3x3 array with random values. **Hint: Use [`np.random.random`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.random.html).** <br><br>\n",
    "5. Comment why this expression `np.nan == np.nan` is False. **Hint: Use stackoverflow.** <br><br>\n",
    "6. Print the `mean` and `standard deviation` of `np2`. **Hint: Use `f-string`, `np.mean`, and `np.var` methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np1 = np.arange( 200, 750)\n",
    "np2 = np.random.normal( 50 , 4, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Replace all the `even_numbers` in `np1` with 100. **Hint: Use `indexing` in arrys and [this filer](https://stackoverflow.com/questions/41638751/filtering-even-numbers-in-python).** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 201 100 203 100 205 100 207 100 209 100 211 100 213 100 215 100 217\n",
      " 100 219 100 221 100 223 100 225 100 227 100 229 100 231 100 233 100 235\n",
      " 100 237 100 239 100 241 100 243 100 245 100 247 100 249 100 251 100 253\n",
      " 100 255 100 257 100 259 100 261 100 263 100 265 100 267 100 269 100 271\n",
      " 100 273 100 275 100 277 100 279 100 281 100 283 100 285 100 287 100 289\n",
      " 100 291 100 293 100 295 100 297 100 299 100 301 100 303 100 305 100 307\n",
      " 100 309 100 311 100 313 100 315 100 317 100 319 100 321 100 323 100 325\n",
      " 100 327 100 329 100 331 100 333 100 335 100 337 100 339 100 341 100 343\n",
      " 100 345 100 347 100 349 100 351 100 353 100 355 100 357 100 359 100 361\n",
      " 100 363 100 365 100 367 100 369 100 371 100 373 100 375 100 377 100 379\n",
      " 100 381 100 383 100 385 100 387 100 389 100 391 100 393 100 395 100 397\n",
      " 100 399 100 401 100 403 100 405 100 407 100 409 100 411 100 413 100 415\n",
      " 100 417 100 419 100 421 100 423 100 425 100 427 100 429 100 431 100 433\n",
      " 100 435 100 437 100 439 100 441 100 443 100 445 100 447 100 449 100 451\n",
      " 100 453 100 455 100 457 100 459 100 461 100 463 100 465 100 467 100 469\n",
      " 100 471 100 473 100 475 100 477 100 479 100 481 100 483 100 485 100 487\n",
      " 100 489 100 491 100 493 100 495 100 497 100 499 100 501 100 503 100 505\n",
      " 100 507 100 509 100 511 100 513 100 515 100 517 100 519 100 521 100 523\n",
      " 100 525 100 527 100 529 100 531 100 533 100 535 100 537 100 539 100 541\n",
      " 100 543 100 545 100 547 100 549 100 551 100 553 100 555 100 557 100 559\n",
      " 100 561 100 563 100 565 100 567 100 569 100 571 100 573 100 575 100 577\n",
      " 100 579 100 581 100 583 100 585 100 587 100 589 100 591 100 593 100 595\n",
      " 100 597 100 599 100 601 100 603 100 605 100 607 100 609 100 611 100 613\n",
      " 100 615 100 617 100 619 100 621 100 623 100 625 100 627 100 629 100 631\n",
      " 100 633 100 635 100 637 100 639 100 641 100 643 100 645 100 647 100 649\n",
      " 100 651 100 653 100 655 100 657 100 659 100 661 100 663 100 665 100 667\n",
      " 100 669 100 671 100 673 100 675 100 677 100 679 100 681 100 683 100 685\n",
      " 100 687 100 689 100 691 100 693 100 695 100 697 100 699 100 701 100 703\n",
      " 100 705 100 707 100 709 100 711 100 713 100 715 100 717 100 719 100 721\n",
      " 100 723 100 725 100 727 100 729 100 731 100 733 100 735 100 737 100 739\n",
      " 100 741 100 743 100 745 100 747 100 749]\n"
     ]
    }
   ],
   "source": [
    "#Using the information of filtering numbers in python in the link in order to replace the even numbers with 100 in np1.\n",
    "np1[np1%2==0]=100  \n",
    "\n",
    "print(np1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a 3x3 matrix with values ranging from 0 to 8. **Hint: Use `np.arange` and `np.reshape` method.** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "matrix= np.arange(0,9,1) #Using the np.arange method to create an array with values from 0 to 8.\n",
    "matrix3x3 = matrix.reshape(3,3) #Using np.reshape method to convert \"matrix\" intro a 3 x 3 matrix. \n",
    "\n",
    "print(matrix3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Consider an array `Z = [1,2,3,4,5,6,7,8,9,10]`, generate an array `R = [ [ 1, 2, 3, 4], [ 2, 3, 4, 5 ], [ 3, 4, 5, 6 ], ..., [ 7, 8, 9, 10 ] ]`?.**Hint: Use `np.arange` and `np.concatenate`** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 2  3  4  5]\n",
      " [ 3  4  5  6]\n",
      " [ 4  5  6  7]\n",
      " [ 5  6  7  8]\n",
      " [ 6  7  8  9]\n",
      " [ 7  8  9 10]]\n",
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "#Using np.arange to create the array Z.\n",
    "Z= np.arange(1,11,1) \n",
    "\n",
    "#Using np.concatenate to create the array R that itÂ´s compouse of 7 arrays created with np.arange.\n",
    "R= np.concatenate(([np.arange(1,5,1)], [np.arange(2,6,1)], [np.arange(3,7,1)], \n",
    "                   [np.arange(4,8,1)], [np.arange(5,9,1)], [np.arange(6,10,1)], \n",
    "                   [np.arange(7,11,1)]))\n",
    "print(R)\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a 3x3x3 array with random values. **Hint: Use [`np.random.random`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.14880371 0.93493605 0.12589912]\n",
      "  [0.00783298 0.36989577 0.74871304]\n",
      "  [0.4600936  0.71611385 0.45843488]]\n",
      "\n",
      " [[0.36561875 0.13795091 0.36002703]\n",
      "  [0.19640615 0.27643201 0.60838082]\n",
      "  [0.0360846  0.57748868 0.5067313 ]]\n",
      "\n",
      " [[0.32010243 0.99972    0.81733106]\n",
      "  [0.31872246 0.45159172 0.11492587]\n",
      "  [0.00721932 0.52319437 0.00552583]]]\n"
     ]
    }
   ],
   "source": [
    "#Using np.random.random in order to create a 3x3x3 array with random values \n",
    "array3x3x3 = np.random.random_sample((3,3,3)) \n",
    "print(array3x3x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Comment why this expression np.nan == np.nan is False. Hint: Use stackoverflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expression np.nan == np.nan is False because np.nan (\"Not a Number\") represents an undefined or unrepresentable value. \n",
    "The value of np.nan is not equal to any value, including itself because its behavior is that when a mathematical operation results in a undefined value such as 0/0 or sqrt(-1) the result is NaN, but that NaN value has not the same origin, so it is not the same NaN value. \n",
    "\n",
    "Because of that, it's not possible to compare two np.nan values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Print the mean and standard deviation of np2. Hint: Use f-string, np.mean, and np.var methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "np2 = np.random.normal( 50 , 4, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.041701524011465\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean (np2)\n",
    "print (mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.45998854909313\n"
     ]
    }
   ],
   "source": [
    "variance = np.var (np2)\n",
    "print (variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8026291627100752\n"
     ]
    }
   ],
   "source": [
    "standard_deviation = np.sqrt (variance)\n",
    "print (standard_deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values on np2 is 50.041701524011465\n",
      "Standar deviation of values on np2 is 3.8026291627100752\n"
     ]
    }
   ],
   "source": [
    "print (f\"Mean of values on np2 is {mean}\")\n",
    "\n",
    "print (f\"Standar deviation of values on np2 is {standard_deviation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restricted Least Squares\n",
    "\n",
    "Given the following equation:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "lnCT &= \\beta_{0}+\\beta_{q}lnq+ \\frac{1}{2}\\beta_{qq} lnq^2+\\beta_{q1}lnqlnp_1+\\beta_{q2}lnqlnp_2+ \\beta_{q3}lnqlnp_{3} +\\beta_{1}lnp_1+\\beta_{2}lnp_2+ \\beta_{3}lnp_3 \\\\\n",
    "& + \\frac{1}{2}\\beta_{11}ln^{2}p_1+ \\frac{1}{2}\\beta_{22}ln^{2}p_{2}+ \\frac{1}{2}\\beta_{33}ln^{2}p_{3} + \\frac{1}{2}\\beta_{12}lnp_{1}lnp_{2}+ \\frac{1}{2}\\beta_{13}lnp_{1}lnp_{3}+\\frac{1}{2}\\beta_{23}lnp_{2}lnp_{3} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "ST: \n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\beta_{1} + \\beta_{2} + \\beta_{3} &= 1 \\\\\n",
    "\\beta_{q1} + \\beta_{q2} + \\beta_{q3} &= 0 \\\\\n",
    "\\beta_{11} + \\beta_{12} + \\beta_{13} &= 0 \\\\\n",
    "\\beta_{21} + \\beta_{22} + \\beta_{23} &= 0 \\\\\n",
    "\\beta_{31} + \\beta_{32} + \\beta_{33} &= 0 \\\\\n",
    "\\beta_{ij} = \\beta_{ji}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Get $\\widehat{\\boldsymbol{\\beta}}^{(RLS)}$ vector from the equation bellow. Use the `q`, `p1`, `p2`, `p3`, `CT` numpies. <br><br>\n",
    "2. Get the `covariance matrix` $\\mathbb{V}{\\rm ar} \\left(\\widehat{\\boldsymbol{\\beta}}^{(RLS)} \\right)$. <br><br>\n",
    "**Hint: For more information about Restricted Least Squares [click here](http://web.vu.lt/mif/a.buteikis/wp-content/uploads/PE_Book/4-4-Multiple-RLS.html).**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "greene = pd.read_csv(r\"/Users/Andre/Documents/GitHub/Diplomado_PUCP/_data/christensen_greene_f4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = greene.COST.values\n",
    "q = greene.Q.values\n",
    "p1 = greene.PL.values\n",
    "p2 = greene.PF.values\n",
    "p3 = greene.PK.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First of all, we need to define the terms in the equation\n",
    "Y = np.log(ct) # This is the term ln(CT)\n",
    "c = np.ones(len(Y)) # This is the constant that has same number of observations, as the number of observations in the independent variable\n",
    "x_q = np.log(q) # This is the dependent variable ln(q)\n",
    "x_qq = np.log(q) * np.log(q) # This is the dependent variable ln(q)^2\n",
    "x_q1 = np.log(q) * np.log(p1) # This is the dependent variable ln(q)*ln(p1)\n",
    "x_q2 = np.log(q) * np.log(p2) # This is the dependent ln(q)*ln(p2)\n",
    "x_q3 = np.log(q) * np.log(p3) # This is the dependent ln(q)*ln(p3)\n",
    "x_p1 = np.log(p1) # This is the dependent variable ln(p1)\n",
    "x_p2 = np.log(p2) # This is the dependent variable ln(p2)\n",
    "x_p3 = np.log(p3) # This is the dependent variable ln(p3)\n",
    "x_p1p1 = 0.5 * np.log(p1) * np.log(p1) # (1/2)*ln(p1)^2\n",
    "x_p2p2 = 0.5 * np.log(p2) * np.log(p2) # (1/2)*ln(p2)^2\n",
    "x_p3p3 = 0.5 * np.log(p3) * np.log(p3) # (1/2)*lnp(p3)^2\n",
    "x_p1p2 = 0.5 * np.log(p1) * np.log(p2) # (1/2)*ln(p1)*ln(p2)\n",
    "x_p1p3 = 0.5 * np.log(p1) * np.log(p3) # (1/2)*ln(p1)*ln(p3)\n",
    "x_p2p3 = 0.5 * np.log(p2) * np.log(p3) # (1/2)*ln(p2)*ln(p3)\n",
    "\n",
    "# Then we define the X matrix and L matrix \n",
    "X = np.asarray([c, x_q, x_qq, x_q1, x_q2,x_q3, x_p1, x_p2, x_p3, x_p1p1, x_p2p2, x_p3p3, x_p1p2, x_p1p3, x_p2p3]).T\n",
    "\n",
    "L = np.array( ([0,0,0,0,0,0,1,1,1,0,0,0,0,0,0],\n",
    "               [0,0,0,1,1,1,0,0,0,0,0,0,0,0,0],\n",
    "               [0,0,0,0,0,0,0,0,0,1,0,0,1,1,0],\n",
    "               [0,0,0,0,0,0,0,0,0,0,1,0,1,0,1],\n",
    "               [0,0,0,0,0,0,0,0,0,0,0,1,0,1,1]) )\n",
    "\n",
    "# Defining the r vector\n",
    "r = np.array( [1, 0, 0, 0, 0] )\n",
    "\n",
    "# According to the theory, the b_rls is equal to b_ols plus a term that considers how much b_ols\n",
    "# doesn't satisfy the restrictions\n",
    "# So first we need to estimate b_ols, then we can estimate b_rls\n",
    "\n",
    "# beta OLS\n",
    "b_ols = np.linalg.inv(X.T @ X) @ (X.T @ Y)\n",
    "\n",
    "# beta RLS\n",
    "b_rls = b_ols - np.linalg.inv(X.T @ X) @ L.T @ np.linalg.inv( L @ np.linalg.inv(X.T @ X) @ L.T) @ (L @ b_ols - r )\n",
    "\n",
    "\n",
    "# Then we label the coefficients\n",
    "betas = [\"beta_0\", \"beta_q\", \"beta_qq\", \"beta_q1\", \"beta_q2\",\n",
    "          \"beta_q3\", \"beta_p1\", \"beta_p2\", \"beta_p3\", \"beta_p1p1\",\n",
    "          \"beta_p2p2\", \"beta_p3p3\", \"beta_p1p2\", \"beta_p1p3\", \"beta_p2p3\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Get $\\widehat{\\boldsymbol{\\beta}}^{(RLS)}$ vector from the equation bellow. Use the `q`, `p1`, `p2`, `p3`, `CT` numpies. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t Results\t\n",
      "Parameter  \t\t OLS  \t\t\t RLS\n",
      "beta_0  \t -76.25926146656275  \t -7.111200145504128\n",
      "beta_q  \t -1.0804253568639979  \t 0.46136798349312924\n",
      "beta_qq  \t 0.026489246416623757  \t 0.02997769675393789\n",
      "beta_q1  \t 0.13104058702720067  \t -0.004354401896267346\n",
      "beta_q2  \t 0.058652203004839976  \t 0.03677797912031289\n",
      "beta_q3  \t 0.04014440021046539  \t -0.032423577224046\n",
      "beta_p1  \t 14.71829254925251  \t 0.21556634414485742\n",
      "beta_p2  \t -0.8947329132352024  \t 0.4029230270343964\n",
      "beta_p3  \t 6.380797025747597  \t 0.3815106288206156\n",
      "beta_p1p1  \t -1.5385273529682308  \t -0.008712239864907545\n",
      "beta_p2p2  \t -0.07350555841912865  \t 0.005155675581659039\n",
      "beta_p3p3  \t -0.3274142669979483  \t -0.015301676695891497\n",
      "beta_p1p2  \t 0.32456578317214735  \t -0.005872556206318769\n",
      "beta_p1p3  \t -1.144100975128822  \t 0.01458479607124219\n",
      "beta_p2p3  \t -0.0480493950744858  \t 0.0007168806246610065\n"
     ]
    }
   ],
   "source": [
    "# Showing the results\n",
    "\n",
    "print('\\t\\t Results\\t')\n",
    "print('Parameter',' \\t\\t' ,'OLS' , ' \\t\\t\\t', 'RLS')\n",
    "print(betas[0]   , ' \\t',b_ols[0], ' \\t', b_rls[0])\n",
    "print(betas[1]   , ' \\t',b_ols[1], ' \\t', b_rls[1])\n",
    "print(betas[2]   , ' \\t',b_ols[2], ' \\t', b_rls[2])\n",
    "print(betas[3]   , ' \\t',b_ols[3], ' \\t', b_rls[3])\n",
    "print(betas[4]   , ' \\t',b_ols[4], ' \\t', b_rls[4])\n",
    "print(betas[5]   , ' \\t',b_ols[5], ' \\t', b_rls[5])\n",
    "print(betas[6]   , ' \\t',b_ols[6], ' \\t', b_rls[6])\n",
    "print(betas[7]   , ' \\t',b_ols[7], ' \\t', b_rls[7])\n",
    "print(betas[8]   , ' \\t',b_ols[8], ' \\t', b_rls[8])\n",
    "print(betas[9]   , ' \\t',b_ols[9], ' \\t', b_rls[9])\n",
    "print(betas[10]   , ' \\t',b_ols[10], ' \\t', b_rls[10])\n",
    "print(betas[11]   , ' \\t',b_ols[11], ' \\t', b_rls[11])\n",
    "print(betas[12]   , ' \\t',b_ols[12], ' \\t', b_rls[12])\n",
    "print(betas[13]   , ' \\t',b_ols[13], ' \\t', b_rls[13])\n",
    "print(betas[14]   , ' \\t',b_ols[14], ' \\t', b_rls[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Get the `covariance matrix` $\\mathbb{V}{\\rm ar} \\left(\\widehat{\\boldsymbol{\\beta}}^{(RLS)} \\right)$. <br><br>\n",
    "**Hint: For more information about Restricted Least Squares [click here](http://web.vu.lt/mif/a.buteikis/wp-content/uploads/PE_Book/4-4-Multiple-RLS.html).**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beta_0</th>\n",
       "      <th>beta_q</th>\n",
       "      <th>beta_qq</th>\n",
       "      <th>beta_q1</th>\n",
       "      <th>beta_q2</th>\n",
       "      <th>beta_q3</th>\n",
       "      <th>beta_p1</th>\n",
       "      <th>beta_p2</th>\n",
       "      <th>beta_p3</th>\n",
       "      <th>beta_p1p1</th>\n",
       "      <th>beta_p2p2</th>\n",
       "      <th>beta_p3p3</th>\n",
       "      <th>beta_p1p2</th>\n",
       "      <th>beta_p1p3</th>\n",
       "      <th>beta_p2p3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta_0</th>\n",
       "      <td>7.648283</td>\n",
       "      <td>-0.086668</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>-0.019922</td>\n",
       "      <td>0.005793</td>\n",
       "      <td>-2.749398</td>\n",
       "      <td>1.454277</td>\n",
       "      <td>1.295121</td>\n",
       "      <td>0.357380</td>\n",
       "      <td>-0.082861</td>\n",
       "      <td>-0.740994</td>\n",
       "      <td>-0.507756</td>\n",
       "      <td>0.150377</td>\n",
       "      <td>0.590617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_q</th>\n",
       "      <td>-0.086668</td>\n",
       "      <td>0.014434</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>-0.013284</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>0.002627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_qq</th>\n",
       "      <td>0.000093</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_q1</th>\n",
       "      <td>0.014129</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_q2</th>\n",
       "      <td>-0.019922</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_q3</th>\n",
       "      <td>0.005793</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p1</th>\n",
       "      <td>-2.749398</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.001241</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>-0.003354</td>\n",
       "      <td>1.037901</td>\n",
       "      <td>-0.531437</td>\n",
       "      <td>-0.506464</td>\n",
       "      <td>-0.141017</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>0.279112</td>\n",
       "      <td>0.189517</td>\n",
       "      <td>-0.048500</td>\n",
       "      <td>-0.230612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p2</th>\n",
       "      <td>1.454277</td>\n",
       "      <td>-0.013284</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>-0.005516</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>-0.531437</td>\n",
       "      <td>0.309258</td>\n",
       "      <td>0.222179</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>-0.154323</td>\n",
       "      <td>-0.111183</td>\n",
       "      <td>0.040845</td>\n",
       "      <td>0.113478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p3</th>\n",
       "      <td>1.295121</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.000292</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>-0.000629</td>\n",
       "      <td>-0.506464</td>\n",
       "      <td>0.222179</td>\n",
       "      <td>0.284285</td>\n",
       "      <td>0.070679</td>\n",
       "      <td>-0.038800</td>\n",
       "      <td>-0.124789</td>\n",
       "      <td>-0.078334</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.117134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p1p1</th>\n",
       "      <td>0.357380</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.000432</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>-0.141017</td>\n",
       "      <td>0.070338</td>\n",
       "      <td>0.070679</td>\n",
       "      <td>0.020010</td>\n",
       "      <td>-0.007440</td>\n",
       "      <td>-0.037810</td>\n",
       "      <td>-0.025190</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.032630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p2p2</th>\n",
       "      <td>-0.082861</td>\n",
       "      <td>-0.002631</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>-0.038800</td>\n",
       "      <td>-0.007440</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>-0.012085</td>\n",
       "      <td>0.019525</td>\n",
       "      <td>-0.013802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p3p3</th>\n",
       "      <td>-0.740994</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>0.279112</td>\n",
       "      <td>-0.154323</td>\n",
       "      <td>-0.124789</td>\n",
       "      <td>-0.037810</td>\n",
       "      <td>-0.005723</td>\n",
       "      <td>0.090825</td>\n",
       "      <td>0.067179</td>\n",
       "      <td>-0.029369</td>\n",
       "      <td>-0.061456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p1p2</th>\n",
       "      <td>-0.507756</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>0.189517</td>\n",
       "      <td>-0.111183</td>\n",
       "      <td>-0.078334</td>\n",
       "      <td>-0.025190</td>\n",
       "      <td>-0.012085</td>\n",
       "      <td>0.067179</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>-0.027037</td>\n",
       "      <td>-0.040142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p1p3</th>\n",
       "      <td>0.150377</td>\n",
       "      <td>-0.001440</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>-0.000032</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>-0.048500</td>\n",
       "      <td>0.040845</td>\n",
       "      <td>0.007655</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>0.019525</td>\n",
       "      <td>-0.029369</td>\n",
       "      <td>-0.027037</td>\n",
       "      <td>0.021857</td>\n",
       "      <td>0.007512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_p2p3</th>\n",
       "      <td>0.590617</td>\n",
       "      <td>0.002627</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>-0.230612</td>\n",
       "      <td>0.113478</td>\n",
       "      <td>0.117134</td>\n",
       "      <td>0.032630</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>-0.061456</td>\n",
       "      <td>-0.040142</td>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.053944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             beta_0    beta_q   beta_qq   beta_q1   beta_q2   beta_q3  \\\n",
       "beta_0     7.648283 -0.086668  0.000093  0.014129 -0.019922  0.005793   \n",
       "beta_q    -0.086668  0.014434 -0.000031 -0.002625  0.002046  0.000579   \n",
       "beta_qq    0.000093 -0.000031  0.000005 -0.000007 -0.000001  0.000008   \n",
       "beta_q1    0.014129 -0.002625 -0.000007  0.000527 -0.000328 -0.000200   \n",
       "beta_q2   -0.019922  0.002046 -0.000001 -0.000328  0.000590 -0.000262   \n",
       "beta_q3    0.005793  0.000579  0.000008 -0.000200 -0.000262  0.000462   \n",
       "beta_p1   -2.749398  0.010989 -0.000017 -0.001241  0.004595 -0.003354   \n",
       "beta_p2    1.454277 -0.013284  0.000068  0.001534 -0.005516  0.003983   \n",
       "beta_p3    1.295121  0.002295 -0.000051 -0.000292  0.000921 -0.000629   \n",
       "beta_p1p1  0.357380  0.001436  0.000011 -0.000432 -0.000300  0.000732   \n",
       "beta_p2p2 -0.082861 -0.002631  0.000028  0.000506  0.000052 -0.000558   \n",
       "beta_p3p3 -0.740994 -0.001187 -0.000044  0.000517  0.000415 -0.000933   \n",
       "beta_p1p2 -0.507756  0.000004 -0.000041  0.000222  0.000332 -0.000553   \n",
       "beta_p1p3  0.150377 -0.001440  0.000030  0.000211 -0.000032 -0.000179   \n",
       "beta_p2p3  0.590617  0.002627  0.000014 -0.000728 -0.000383  0.001111   \n",
       "\n",
       "            beta_p1   beta_p2   beta_p3  beta_p1p1  beta_p2p2  beta_p3p3  \\\n",
       "beta_0    -2.749398  1.454277  1.295121   0.357380  -0.082861  -0.740994   \n",
       "beta_q     0.010989 -0.013284  0.002295   0.001436  -0.002631  -0.001187   \n",
       "beta_qq   -0.000017  0.000068 -0.000051   0.000011   0.000028  -0.000044   \n",
       "beta_q1   -0.001241  0.001534 -0.000292  -0.000432   0.000506   0.000517   \n",
       "beta_q2    0.004595 -0.005516  0.000921  -0.000300   0.000052   0.000415   \n",
       "beta_q3   -0.003354  0.003983 -0.000629   0.000732  -0.000558  -0.000933   \n",
       "beta_p1    1.037901 -0.531437 -0.506464  -0.141017   0.041095   0.279112   \n",
       "beta_p2   -0.531437  0.309258  0.222179   0.070338  -0.002296  -0.154323   \n",
       "beta_p3   -0.506464  0.222179  0.284285   0.070679  -0.038800  -0.124789   \n",
       "beta_p1p1 -0.141017  0.070338  0.070679   0.020010  -0.007440  -0.037810   \n",
       "beta_p2p2  0.041095 -0.002296 -0.038800  -0.007440   0.025888  -0.005723   \n",
       "beta_p3p3  0.279112 -0.154323 -0.124789  -0.037810  -0.005723   0.090825   \n",
       "beta_p1p2  0.189517 -0.111183 -0.078334  -0.025190  -0.012085   0.067179   \n",
       "beta_p1p3 -0.048500  0.040845  0.007655   0.005180   0.019525  -0.029369   \n",
       "beta_p2p3 -0.230612  0.113478  0.117134   0.032630  -0.013802  -0.061456   \n",
       "\n",
       "           beta_p1p2  beta_p1p3  beta_p2p3  \n",
       "beta_0     -0.507756   0.150377   0.590617  \n",
       "beta_q      0.000004  -0.001440   0.002627  \n",
       "beta_qq    -0.000041   0.000030   0.000014  \n",
       "beta_q1     0.000222   0.000211  -0.000728  \n",
       "beta_q2     0.000332  -0.000032  -0.000383  \n",
       "beta_q3    -0.000553  -0.000179   0.001111  \n",
       "beta_p1     0.189517  -0.048500  -0.230612  \n",
       "beta_p2    -0.111183   0.040845   0.113478  \n",
       "beta_p3    -0.078334   0.007655   0.117134  \n",
       "beta_p1p1  -0.025190   0.005180   0.032630  \n",
       "beta_p2p2  -0.012085   0.019525  -0.013802  \n",
       "beta_p3p3   0.067179  -0.029369  -0.061456  \n",
       "beta_p1p2   0.052227  -0.027037  -0.040142  \n",
       "beta_p1p3  -0.027037   0.021857   0.007512  \n",
       "beta_p2p3  -0.040142   0.007512   0.053944  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To estimate the covariance matrix we need to estimate the vector of residuals and the standart deviation\n",
    "# Defining errors and variance\n",
    "residuals = Y - X @ b_ols\n",
    "sigma_sqr = ( residuals.T @ residuals) / (len(Y)-(len(X[0])+1))\n",
    "\n",
    "# getting var_beta_rls\n",
    "var_b_rls = sigma_sqr * np.linalg.inv(X.T @ X) - sigma_sqr * np.linalg.inv(X.T @ X) @ L.T @ np.linalg.inv( L @ np.linalg.inv(X.T @ X) @ L.T) @ L @ np.linalg.inv(X.T @ X)\n",
    "\n",
    "# Finally we show the var-cov coef. matrix\n",
    "vbr = pd.DataFrame(var_b_rls)\n",
    "vbr.columns = betas\n",
    "vbr.index = betas\n",
    "vbr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code bellow uncomment the second line to install savReaderWriter library. The `dict_varlabels` has the labels of the columns of rec1.\n",
    "\n",
    "1. Check if CASEID identifies each observation uniquely. **[Hint: Use is_unique method.](https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html)**\n",
    "2. Make the CASEID column the index of your data set. **[Hint: Use set_index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html)**. \n",
    "3. Keep women who are 15-30 years old and live in Urban areas. **[Hint: Use query](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)**.\n",
    "4. Generate a new column with the month of born. Just use the first three letters.  Use the English names of the months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read REC0111 data\n",
    "#!pip install savReaderWriter\n",
    "import savReaderWriter as sav\n",
    "rec1 = pd.read_spss( fr\"../../_data/endes/2019/REC0111.sav\" )\n",
    "\n",
    "# Get labels from sav file\n",
    "with sav.SavHeaderReader( fr\"../../_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "\n",
    "dict_varlabels = metadata[3]\n",
    "dict_varlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: savReaderWriter in c:\\users\\hecto\\anaconda3\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: pyreadstat in c:\\users\\hecto\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\hecto\\anaconda3\\lib\\site-packages (from pyreadstat) (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hecto\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\hecto\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hecto\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hecto\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ID1': 'AÃ±o',\n",
       " 'HHID': 'IdentificaciÃ³n Cuestionario del Hogar',\n",
       " 'CASEID': 'IdentificaciÃ³n Cuestionario Individual',\n",
       " 'V001': 'Conglomerado',\n",
       " 'V002': 'NÃºmero de vivienda',\n",
       " 'V003': 'NÃºmero de lÃ­nea de entrevistada',\n",
       " 'V004': 'Unidad de Ã¡rea final',\n",
       " 'V007': 'AÃ±o de la entrevista',\n",
       " 'V008': 'Fecha de la entrevista, CodificaciÃ³n centenaria de meses (CMC)',\n",
       " 'V009': 'Mes de nacimiento de la entrevistada',\n",
       " 'V010': 'AÃ±o de nacimiento de la entrevistada',\n",
       " 'V011': 'Fecha de nacimiento, CodificaciÃ³n centenaria de meses (CMC)',\n",
       " 'V012': 'Edad actual - entrevistada',\n",
       " 'V013': 'Edad actual por grupos de 5 aÃ±os',\n",
       " 'V014': 'Integridad de la informaciÃ³n para la fecha de nacimiento ',\n",
       " 'V015': 'Resultado entrevista individual',\n",
       " 'V017': 'Inicio del calendario, CodificaciÃ³n centenaria de mesesl CMC',\n",
       " 'V018': 'Columna del mes de la entrevista',\n",
       " 'V019': 'DuraciÃ³n del calendario',\n",
       " 'V019A': 'NÃºmero de columnas de calendario',\n",
       " 'V020': 'Muestra alguna vez casada',\n",
       " 'V021': 'Unidad de muestreo primario - conglomerado',\n",
       " 'V023': 'Dominio de ejemplo - Departamento',\n",
       " 'V024': 'RegiÃ³n',\n",
       " 'V025': 'Tipo de lugar de residencia',\n",
       " 'V026': 'El lugar de residencia en el que se entrevistÃ³ - De Facto',\n",
       " 'V027': 'NÃºmero de visitas',\n",
       " 'V028': 'IdentificaciÃ³n del entrevistador',\n",
       " 'V029': 'Identificador del digitador',\n",
       " 'V030': 'Supervisor de campo',\n",
       " 'V031': 'Editor de campo',\n",
       " 'V032': 'Editor de la oficina',\n",
       " 'V033': 'SelecciÃ³n final del Ã¡rea de probabilidad',\n",
       " 'V034': 'NÃºmero de orden del esposo',\n",
       " 'V040': 'Altitud del conglomerado en metros',\n",
       " 'V042': 'SelecciÃ³n de hogar para hemoglobina',\n",
       " 'V043': 'SelecciÃ³n para mÃ³dulo de estatus de mujeres',\n",
       " 'V044': 'SelecciÃ³n para mÃ³dulo de violencia domestica',\n",
       " 'V000': 'CÃ³digo y fase del paÃ­s',\n",
       " 'Q105DD': 'Dia de nacimeinto de la entrevistada',\n",
       " 'V101': 'RegiÃ³n',\n",
       " 'V102': 'Tipo de lugar de residencia',\n",
       " 'V103': 'Lugar de residencia de la infancia',\n",
       " 'V104': 'Cuanto tiempo tiene viviendo continuamente en el lugar de residencia actual',\n",
       " 'V105': 'Tipo de lugar de residencia anteriormente',\n",
       " 'V106': 'Nivel educativo mÃ¡s alto',\n",
       " 'V107': 'AÃ±o/grado de educaciÃ³n mÃ¡s alto aprobado',\n",
       " 'V113': 'Fuente principal de abasteciemiento de agua potable que utilizan en su hogar para tomar o beber',\n",
       " 'V115': 'Tiempo para llegar a la fuente de agua',\n",
       " 'V116': 'Tipo de instalaciÃ³n sanitaria',\n",
       " 'V119': 'En su hogar tiene: electricidad',\n",
       " 'V120': 'En su hogar tiene: radio',\n",
       " 'V121': 'En su hogar tiene: televisiÃ³n',\n",
       " 'V122': 'En su hogar tiene: refrigerador',\n",
       " 'V123': 'En su hogar tiene: bicicleta',\n",
       " 'V124': 'En su hogar tiene: motocicleta/motocar',\n",
       " 'V125': 'En su hogar tiene: coche/camiÃ³n',\n",
       " 'V127': 'Material predominante del piso de la vivienda',\n",
       " 'V128': 'Material predominante de las paredes exteriores de la vivienda',\n",
       " 'V129': 'Material predominante del techo de la vivienda',\n",
       " 'V130': 'ReligiÃ³n',\n",
       " 'V131': 'Etnicidad',\n",
       " 'V133': 'EducaciÃ³n en aÃ±os simples',\n",
       " 'V134': 'El lugar en el que se realizÃ³ la entrevista  De-facto',\n",
       " 'V135': 'Residente habitual o visitante',\n",
       " 'V136': 'NÃºmero de miembros del hogar',\n",
       " 'V137': 'NÃºmero de niÃ±os de 6 aÃ±os de edad ',\n",
       " 'V138': 'NÃºmero de mujeres de 15 a 49 aÃ±os de edad elegibles en el hogar ',\n",
       " 'V139': 'RegiÃ³n, residencia habitual De-jure',\n",
       " 'V140': 'Tipo de Ã¡rea de residencia De-jure',\n",
       " 'V141': 'Lugar de residencia De-jure',\n",
       " 'V149': 'Logro educativo',\n",
       " 'V150': 'RelaciÃ³n con el jefe del hogar',\n",
       " 'V151': 'Sexo del Jefe del Hogar',\n",
       " 'V152': 'Edad del jefe del hogar',\n",
       " 'V153': 'En su hogar tiene: telÃ©fono',\n",
       " 'AWFACTT': 'Factor todas las mujeres - total',\n",
       " 'AWFACTU': 'Factor todas las mujeres - urbano/rural',\n",
       " 'AWFACTR': 'Factor todas las mujeres - regional',\n",
       " 'AWFACTE': 'Factor todas las mujeres - educaciÃ³n',\n",
       " 'AWFACTW': 'Factor todas las mujeres - Ã­ndice de riqueza',\n",
       " 'V155': 'AlfabetizaciÃ³n',\n",
       " 'V156': 'Alguna vez participÃ³ en un programa de alfabetizaciÃ³n (no incluyendo la escuela primaria)',\n",
       " 'V157': 'Frecuencia de lectura de un periÃ³dico o revista',\n",
       " 'V158': 'Frecuencia de escuchar radio',\n",
       " 'V159': 'Frecuencia de ver televisiÃ³n',\n",
       " 'V160': 'BaÃ±o compartido con otros hogares',\n",
       " 'V161': 'Tipo de combustible para cocinar',\n",
       " 'V166': 'Resultados de la prueba del yodo en la sal',\n",
       " 'V167': 'NÃºmero de viajes en los Ãºltimos 12 meses',\n",
       " 'V168': 'Afuera mÃ¡s de un mes en los Ãºltimos 12 meses',\n",
       " 'ML101': 'Tipo de mosquitero que utilizo para dormir Ãºltima noche',\n",
       " 'QD333_1': 'Alguna dificultad o limitaciÃ³n permanente para ver, aÃºn usando anteojos',\n",
       " 'QD333_2': 'Alguna dificultad o limitaciÃ³n permanente para oir, aÃºn usando audÃ­fonos',\n",
       " 'QD333_3': 'Alguna dificultad o limitaciÃ³n permanente para hablar o comunicarse, aÃºn usando la lengua de seÃ±as u otro',\n",
       " 'QD333_4': 'Alguna dificultad o limitaciÃ³n permanente para moverse o caminar para usar brazos y/o piernas',\n",
       " 'QD333_5': 'Alguna dificultad o limitaciÃ³n permanente para entender o aprender (concentrarse y recordarse)',\n",
       " 'QD333_6': 'Alguna dificultad o limitaciÃ³n permanente para relacionarse con los demÃ¡s, por sus pensamientos, sentimientos, emociones o conductas',\n",
       " 'UBIGEO': 'CÃ³digo de UbicaciÃ³n GegrÃ¡fica',\n",
       " 'V022': 'Estratos',\n",
       " 'V005': 'Factor de ponderacion',\n",
       " 'V190': 'Ãndice de riqueza',\n",
       " 'V191': 'Factor de puntuaciÃ³n del Ã­ndice de riqueza (5 decimales)',\n",
       " 'mujeres12a49': 'Mujeres de 12 a 49 aÃ±os de edad',\n",
       " 'NCONGLOME': 'NÃºmero de Conglomerado (proveniente del marco)'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Firstly we import pandas as \"pd\" and install the libraries \"savReaderWriter\" and \"pyreadstat\". Both are used for reading SPSS files with Python and allow us to read theses files with pandas data frame.\n",
    "import pandas as pd\n",
    "!pip install savReaderWriter\n",
    "!pip install pyreadstat\n",
    "\n",
    "#Now we import \"savReaderWriter\" as \"sav\" and open \"REC0111.sav\" as a pandas dataframe \"rec1\"\n",
    "import savReaderWriter as sav\n",
    "rec1 = pd.read_spss( fr\"C:/Users/hecto/OneDrive/Documents/GitHub/Diplomado_PUCP/_data/endes/2019/REC0111.sav\" )\n",
    "\n",
    "#Now we get labels from sav file\n",
    "with sav.SavHeaderReader( fr\"C:/Users/hecto/OneDrive/Documents/GitHub/Diplomado_PUCP/_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "\n",
    "#Here we can see the labels of the variables (or column headers) of the dataframe\n",
    "dict_varlabels = metadata[3]\n",
    "dict_varlabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check if CASEID identifies each observation uniquely. **[Hint: Use is_unique method.](https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASEID column identifies each observation uniquely\n"
     ]
    }
   ],
   "source": [
    "#It is important to know if \"CASEID\" column has unique observations because we will make it our index column.\n",
    "#If the index column is not unique, which means that it has duplicate rows with the same index value, can lead to confusion and errors when trying to manipulate the data. Also can bring issues when trying to merge data with other dataframes. \n",
    "#It is important to ensure that the index is unique to maintain the integrity and accuracy of the data in the dataframe.\n",
    "\n",
    "#We use the is_unique method to check if the \"CASEID\" column each observation uniquely.\n",
    "if rec1[\"CASEID\"].is_unique:\n",
    "    print(\"CASEID column identifies each observation uniquely\")\n",
    "else:\n",
    "    print(\"CASEID column does not identify each observation uniquely\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Make the CASEID column the index of your data set. **[Hint: Use set_index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the set_index method to set as index the \"CASEID\" column.\n",
    "rec1=rec1.set_index(\"CASEID\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASEID is the index of the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "#We verify that the \"CASEID\" is now the index column with the .index.name method.\n",
    "if rec1.index.name == 'CASEID':\n",
    "    print(\"CASEID is the index of the DataFrame.\")\n",
    "else:\n",
    "    print(\"CASEID is not the index of the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Keep women who are 15-30 years old and live in Urban areas. **[Hint: Use query](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urbano    26133\n",
      "Rural     10789\n",
      "Name: V102, dtype: int64\n",
      "De 25 a 29 aÃ±os de edad    5836\n",
      "De 30 a 34 aÃ±os de edad    5808\n",
      "De 20 a 24 aÃ±os de edad    5350\n",
      "De 35 a 39 aÃ±os de edad    4951\n",
      "De 15 a 19 aÃ±os de edad    4668\n",
      "De 40 a 44 aÃ±os de edad    3892\n",
      "De 12 a 14 aÃ±os de edad    3633\n",
      "De 45 a 49 aÃ±os de edad    2784\n",
      "Name: V013, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#First, we analyze the \"V102\" and \"V013\" variables, which describe whether the place of residence is rural or urban and the age group of the interviewees respectively. We use for this the .value_counts() method.\n",
    "urban_counts = rec1[\"V102\"].value_counts()\n",
    "print(urban_counts)\n",
    "age_counts = rec1[\"V013\"].value_counts()\n",
    "print(age_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Urbano    11327\n",
      "Rural         0\n",
      "Name: V102, dtype: int64\n",
      "De 25 a 29 aÃ±os de edad    4306\n",
      "De 20 a 24 aÃ±os de edad    3864\n",
      "De 15 a 19 aÃ±os de edad    3157\n",
      "De 12 a 14 aÃ±os de edad       0\n",
      "De 30 a 34 aÃ±os de edad       0\n",
      "De 35 a 39 aÃ±os de edad       0\n",
      "De 40 a 44 aÃ±os de edad       0\n",
      "De 45 a 49 aÃ±os de edad       0\n",
      "Name: V013, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We use the query() method to filter the data based on specific conditions. \n",
    "#In this case we keep all the observations where the interviewees live in a urban area and are between 15 and 30 years old. \n",
    "rec1 = rec1.query(\"V013 in ['De 15 a 19 aÃ±os de edad', 'De 20 a 24 aÃ±os de edad', 'De 25 a 29 aÃ±os de edad'] and V102 == 'Urbano' \")\n",
    "\n",
    "#We confirm the changes done on the observations in the dataframe\n",
    "urban_counts = rec1[\"V102\"].value_counts()\n",
    "print(urban_counts)\n",
    "age_counts = rec1[\"V013\"].value_counts()\n",
    "print(age_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Generate a new column with the month of born. Just use the first three letters.  Use the English names of the months. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CASEID\n",
      "      000104801  2     5.0\n",
      "      000116701  1     6.0\n",
      "      000119101  1     9.0\n",
      "      000203001  2     5.0\n",
      "      000204001  3     9.0\n",
      "                      ... \n",
      "      324202401  2     2.0\n",
      "      324202501  3     5.0\n",
      "      324203901  1     8.0\n",
      "      324204501  2     5.0\n",
      "      324206901  3    10.0\n",
      "Name: V009, Length: 11327, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#First, we analyze the variable \"V009\" which has the label of \"Interviewee's month of birth\"\n",
    "print(rec1.V009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0     1025\n",
      "8.0     1002\n",
      "3.0     1000\n",
      "5.0      991\n",
      "6.0      986\n",
      "7.0      968\n",
      "4.0      946\n",
      "12.0     917\n",
      "10.0     889\n",
      "11.0     874\n",
      "1.0      870\n",
      "2.0      859\n",
      "Name: V009, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "month_counts = rec1[\"V009\"].value_counts()\n",
    "print(month_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sep    1025\n",
      "Aug    1002\n",
      "Mar    1000\n",
      "May     991\n",
      "Jun     986\n",
      "Jul     968\n",
      "Apr     946\n",
      "Dec     917\n",
      "Oct     889\n",
      "Nov     874\n",
      "Jan     870\n",
      "Feb     859\n",
      "Name: month_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#We can see that the \"V009\" column has numbers representing the order number of the months.\n",
    "#In that way, we use the replace() method and create the column \"month_name\", which uses the number of the month from \"V009\" and replaces it with the first three letters of the month name in English. \n",
    "rec1[\"month_name\"] = rec1[\"V009\"].replace({\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec'\n",
    "})\n",
    "\n",
    "#We verify the column created:\n",
    "month_name_counts = rec1[\"month_name\"].value_counts()\n",
    "print(month_name_counts)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
