{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment\n",
    "\n",
    "It is totally prohibited to use any kind of loop. You can use stackoverflow. If you copy codes from previous answers, explain each step. No explanation is `0 points`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dictionaries\n",
    "1. Create a dictionary with two keys: `even_numbers` and `odd_numbers`. The first key should have all the even numbers in this range `[0, 2000]`, and the second key must have all the odd numbers in this range `[9000, 19000]`. The values should be stored in a `list`. **Hint: Use the `np.arange`, `zip`, and `np.tolist()` functions.** <br><br>\n",
    "2. Print the value of `brand` key of `car` dictionary. **Hint: Use the `get` method.** <br><br>\n",
    "3. Print all the the values of `brand` key of `car` dictionary. **Hint: Use the `values` method.** <br><br>\n",
    "4. Print the max value  of `friday` in `january` of `hr_sleep` dictionary. **Hint: [Indexing in nested dictioanries](https://stackoverflow.com/questions/25836376/how-to-get-the-inner-indexes-of-a-nested-dictionary-in-python).** <br><br>\n",
    "5. Add `march` key to the `hr_sleep` dictionary using `week1` and `values2` Python lists. **Hint: Use `zip` function adn [this link](https://stackoverflow.com/questions/1024847/how-can-i-add-new-keys-to-a-dictionary).** <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"model\": \"Mustang\",\n",
    "  \"year\": 1964\n",
    "}\n",
    "\n",
    "hr_sleep = {\"january\": {\"wednesday\": 7,\n",
    "                      \"thursday\": 8,\n",
    "                      \"friday\": [2, 2, 1, 2]},\n",
    "          \"february\": {\"saturday\": 5,\n",
    "                       \"sunday\": 10,\n",
    "                       \"monday\": 8\n",
    "          }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "week1 = ['monday', 'sunday']\n",
    "values2 = [ [2, 3, 4 ] , 8, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ford'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pregunta 2\n",
    "car.get(\"brand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Ford', 'Mustang', 1964])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pregunta 3\n",
    "car.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Numpy\n",
    "1. Replace all the `even_numbers` in `np1` with 100. **Hint: Use `indexing` in arrys and [this filer](https://stackoverflow.com/questions/41638751/filtering-even-numbers-in-python).** <br><br>\n",
    "2. Create a 3x3 matrix with values ranging from 0 to 8. **Hint: Use `np.arange` and `np.reshape` method.** <br><br>\n",
    "3. Consider an array `Z = [1,2,3,4,5,6,7,8,9,10]`, generate an array `R = [ [ 1, 2, 3, 4], [ 2, 3, 4, 5 ], [ 3, 4, 5, 6 ], ..., [ 7, 8, 9, 10 ] ]`?.**Hint: Use `np.arange` and `np.concatenate`** <br><br>\n",
    "4. Create a 3x3x3 array with random values. **Hint: Use [`np.random.random`](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.random.html).** <br><br>\n",
    "5. Comment why this expression `np.nan == np.nan` is False. **Hint: Use stackoverflow.** <br><br>\n",
    "6. Print the `mean` and `standard deviation` of `np2`. **Hint: Use `f-string`, `np.mean`, and `np.var` methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np1 = np.arange( 200, 750)\n",
    "np2 = np.random.normal( 50 , 4, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Restricted Least Squares\n",
    "\n",
    "Given the following equation:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned} \n",
    "lnCT &= \\beta_{0}+\\beta_{q}lnq+ \\frac{1}{2}\\beta_{qq} lnq^2+\\beta_{q1}lnqlnp_1+\\beta_{q2}lnqlnp_2+ \\beta_{q3}lnqlnp_{3} +\\beta_{1}lnp_1+\\beta_{2}lnp_2+ \\beta_{3}lnp_3 \\\\\n",
    "& + \\frac{1}{2}\\beta_{11}ln^{2}p_1+ \\frac{1}{2}\\beta_{22}ln^{2}p_{2}+ \\frac{1}{2}\\beta_{33}ln^{2}p_{3} + \\frac{1}{2}\\beta_{12}lnp_{1}lnp_{2}+ \\frac{1}{2}\\beta_{13}lnp_{1}lnp_{3}+\\frac{1}{2}\\beta_{23}lnp_{2}lnp_{3} \n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "ST: \n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{aligned} \n",
    "\\beta_{1} + \\beta_{2} + \\beta_{3} &= 1 \\\\\n",
    "\\beta_{q1} + \\beta_{q2} + \\beta_{q3} &= 0 \\\\\n",
    "\\beta_{11} + \\beta_{12} + \\beta_{13} &= 0 \\\\\n",
    "\\beta_{21} + \\beta_{22} + \\beta_{23} &= 0 \\\\\n",
    "\\beta_{31} + \\beta_{32} + \\beta_{33} &= 0 \\\\\n",
    "\\beta_{ij} = \\beta_{ji}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. Get $\\widehat{\\boldsymbol{\\beta}}^{(RLS)}$ vector from the equation bellow. Use the `q`, `p1`, `p2`, `p3`, `CT` numpies. <br><br>\n",
    "2. Get the `covariance matrix` $\\mathbb{V}{\\rm ar} \\left(\\widehat{\\boldsymbol{\\beta}}^{(RLS)} \\right)$. <br><br>\n",
    "**Hint: For more information about Restricted Least Squares [click here](http://web.vu.lt/mif/a.buteikis/wp-content/uploads/PE_Book/4-4-Multiple-RLS.html).**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get 洧량틙(洧녠洧洧녡) vector from the equation bellow. Use the q, p1, p2, p3, CT numpies.\n",
    "\n",
    "# First we import the relevant libraries:\n",
    "\n",
    "import numpy as np\n",
    "from math import log\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we import the dataset considering the proposed name \"greene\"\n",
    "greene = pd.read_csv(r\"/Users/joselinchavez/Documents/GitHub/Diplomado_PUCP/Lecture_3/christensen_greene_f4.csv\")\n",
    "\n",
    "#In this case we use the path to the folder where the database \n",
    "#is stored because it couldn't be taken directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>COST</th>\n",
       "      <th>Q</th>\n",
       "      <th>PL</th>\n",
       "      <th>SL</th>\n",
       "      <th>PK</th>\n",
       "      <th>SK</th>\n",
       "      <th>PF</th>\n",
       "      <th>SF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.0</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>127.208861</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>53.269962</td>\n",
       "      <td>10469.410759</td>\n",
       "      <td>8001.863228</td>\n",
       "      <td>0.138972</td>\n",
       "      <td>71.421063</td>\n",
       "      <td>0.226387</td>\n",
       "      <td>30.745785</td>\n",
       "      <td>0.632355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>60.792333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.059326</td>\n",
       "      <td>15187.520802</td>\n",
       "      <td>1398.837478</td>\n",
       "      <td>0.054735</td>\n",
       "      <td>11.977489</td>\n",
       "      <td>0.060836</td>\n",
       "      <td>7.943089</td>\n",
       "      <td>0.083324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5063.490000</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>31.725000</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.243500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>78.500000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>10.221050</td>\n",
       "      <td>1971.000000</td>\n",
       "      <td>6975.177500</td>\n",
       "      <td>0.099725</td>\n",
       "      <td>67.605000</td>\n",
       "      <td>0.192550</td>\n",
       "      <td>24.477350</td>\n",
       "      <td>0.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>138.500000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>25.545400</td>\n",
       "      <td>5645.500000</td>\n",
       "      <td>7890.185000</td>\n",
       "      <td>0.123100</td>\n",
       "      <td>74.120000</td>\n",
       "      <td>0.218600</td>\n",
       "      <td>30.657900</td>\n",
       "      <td>0.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>178.750000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>55.315900</td>\n",
       "      <td>12365.750000</td>\n",
       "      <td>8855.230000</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>78.794250</td>\n",
       "      <td>0.252775</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.686900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>218.000000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>737.408800</td>\n",
       "      <td>115500.000000</td>\n",
       "      <td>13044.000000</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>92.650000</td>\n",
       "      <td>0.457100</td>\n",
       "      <td>51.463000</td>\n",
       "      <td>0.813600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id    YEAR        COST              Q            PL  \\\n",
       "count  158.000000   158.0  158.000000     158.000000    158.000000   \n",
       "mean   127.208861  1970.0   53.269962   10469.410759   8001.863228   \n",
       "std     60.792333     0.0   87.059326   15187.520802   1398.837478   \n",
       "min      1.000000  1970.0    0.130400       4.000000   5063.490000   \n",
       "25%     78.500000  1970.0   10.221050    1971.000000   6975.177500   \n",
       "50%    138.500000  1970.0   25.545400    5645.500000   7890.185000   \n",
       "75%    178.750000  1970.0   55.315900   12365.750000   8855.230000   \n",
       "max    218.000000  1970.0  737.408800  115500.000000  13044.000000   \n",
       "\n",
       "               SL          PK          SK          PF         SF   \n",
       "count  158.000000  158.000000  158.000000  158.000000  158.000000  \n",
       "mean     0.138972   71.421063    0.226387   30.745785    0.632355  \n",
       "std      0.054735   11.977489    0.060836    7.943089    0.083324  \n",
       "min      0.045900   31.725000    0.092400    9.000000    0.243500  \n",
       "25%      0.099725   67.605000    0.192550   24.477350    0.590100  \n",
       "50%      0.123100   74.120000    0.218600   30.657900    0.645000  \n",
       "75%      0.169800   78.794250    0.252775   36.000000    0.686900  \n",
       "max      0.329100   92.650000    0.457100   51.463000    0.813600  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can check the database\n",
    "greene.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the provided renaming:\n",
    "ct = greene.COST.values\n",
    "q = greene.Q.values\n",
    "p1 = greene.PL.values\n",
    "p2 = greene.PF.values\n",
    "p3 = greene.PK.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also took logs of the relevant variables (14 variables \n",
    "# without the intercept, independents) and we can give it the same form as \n",
    "#requested by proposed equation \n",
    "\n",
    "ln_q = np.log(q)\n",
    "ln2_q = 0.5*np.square(ln_q) # in this case we need the additional \n",
    "# square to logarithm\n",
    "\n",
    "ln_p1 = np.log(p1)\n",
    "ln_p2 = np.log(p2)\n",
    "ln_p3 = np.log(p3)\n",
    "\n",
    "ln_qp1 = np.multiply(ln_q, ln_p1) # in this case we need to multiply\n",
    "# adittional to logarithm\n",
    "ln_qp2 = np.multiply(ln_q, ln_p2)\n",
    "ln_qp3 = np.multiply(ln_q, ln_p3)\n",
    "\n",
    "ln2_p1 = 0.5*np.square(ln_p1)\n",
    "ln2_p2 = 0.5*np.square(ln_p2)\n",
    "ln2_p3 = 0.5*np.square(ln_p3)\n",
    "\n",
    "ln_p1p2 = np.multiply(ln_p1, ln_p2)\n",
    "ln_p1p3 = np.multiply(ln_p1, ln_p3)\n",
    "ln_p2p3 = np.multiply(ln_p2, ln_p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create the intercept with the function ones:\n",
    "intercept = np.ones((len(q), 1))\n",
    "#intercept\n",
    "\n",
    "# Likewise, we take logarithm of the dependent variable:\n",
    "ln_ct = np.log(ct)\n",
    "#ln_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  2.07944154,  2.16203856, ..., 25.53597848,\n",
       "        36.87257416, 12.06308434],\n",
       "       [ 1.        ,  6.76734313, 22.89846649, ..., 27.52922179,\n",
       "        38.14391527, 12.86998372],\n",
       "       [ 1.        ,  7.25276242, 26.30128135, ..., 33.47177703,\n",
       "        33.28867699, 13.81021534],\n",
       "       ...,\n",
       "       [ 1.        ,  5.96870756, 17.81273497, ..., 32.93311772,\n",
       "        37.80502354, 16.56284231],\n",
       "       [ 1.        ,  8.57866451, 36.79674242, ..., 34.23242826,\n",
       "        39.94379007, 16.26769248],\n",
       "       [ 1.        ,  9.63036563, 46.3719711 , ..., 28.72378963,\n",
       "        38.10118094, 13.96783596]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We must also create the big X matrix, it must contain the 14 \n",
    "# variables and the intercept, so we use the function stack for columns\n",
    "\n",
    "X_big = np.column_stack([intercept, ln_q, ln2_q, ln_qp1, ln_qp2, \n",
    "                         ln_qp3, ln_p1, ln_p2, ln_p3, ln2_p1, ln2_p2,\n",
    "                         ln2_p3, ln_p1p2, ln_p1p3, ln_p2p3])\n",
    "\n",
    "X_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1]]\n",
      "[1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# To estimate the 洧량틙(洧녠洧洧녡) we should introduce the restrictions in a matrix called L \n",
    "# (similar to the hint). Actually, we can verify that some betas doesn't exist for the\n",
    "# third, fourth, and fifth restrictions, so the last constraint is implicitly introduced on these \n",
    "\n",
    "L = np.array( ( [ 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0 ],\n",
    "                [ 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0 ], \n",
    "                [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0 ], \n",
    "                [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1 ], \n",
    "                [ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1 ] ) )\n",
    "\n",
    "rr = [ 1, 0, 0, 0, 0 ]\n",
    "\n",
    "print(L)\n",
    "print(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We implementing the total database:\n",
    "data_smpl = pd.DataFrame(np.column_stack([ln_ct, X_big]), columns = [\"ln_ct\",\"intercept\", \"ln_q\", \"ln2_q\", \n",
    "                                                                     \"ln_qp1\", \"ln_qp2\", \"ln_qp3\", \"ln_p1\", \n",
    "                                                                     \"ln_p2\", \"ln_p3\", \"ln2_p1\", \"ln2_p2\",\n",
    "                                                                     \"ln2_p3\", \"ln_p1p2\", \"ln_p1p3\", \"ln_p2p3\"])\n",
    "#data_smpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  0\n",
      "intercept -7.111200\n",
      "ln_q       0.461368\n",
      "ln2_q      0.059955\n",
      "ln_qp1    -0.004354\n",
      "ln_qp2     0.036778\n",
      "ln_qp3    -0.032424\n",
      "ln_p1      0.215566\n",
      "ln_p2      0.402923\n",
      "ln_p3      0.381511\n",
      "ln2_p1    -0.004356\n",
      "ln2_p2     0.002578\n",
      "ln2_p3    -0.007651\n",
      "ln_p1p2   -0.002936\n",
      "ln_p1p3    0.007292\n",
      "ln_p2p3    0.000358\n"
     ]
    }
   ],
   "source": [
    "# Now we calculate the usual BETA_ols\n",
    "XTX_inv  = np.linalg.inv(np.dot(np.transpose(X_big), X_big))\n",
    "BETAS_ols = np.dot(XTX_inv, np.dot(np.transpose(X_big), ln_ct))\n",
    "\n",
    "#Nevertheless, we need to calculate the RLS estimator expressed as _RLS = _OLS + \"Restriction Adjustment\"\n",
    "RA_1 = np.dot(XTX_inv, np.transpose(L))\n",
    "RA_2 = np.linalg.inv(np.linalg.multi_dot([L, XTX_inv, np.transpose(L)]))\n",
    "RA_3 = np.dot(L, BETAS_ols) - np.array(rr)\n",
    "RA   = RA_1.dot(RA_2).dot(RA_3)\n",
    "\n",
    "# With this adjustment component, we can finally calculate the RLS estimator:\n",
    "BETAS_rls = BETAS_ols - RA\n",
    "print(pd.DataFrame(BETAS_rls, index = [\"intercept\", \"ln_q\", \"ln2_q\", \"ln_qp1\", \"ln_qp2\", \"ln_qp3\", \"ln_p1\", \n",
    "                                \"ln_p2\", \"ln_p3\", \"ln2_p1\", \"ln2_p2\", \"ln2_p3\", \"ln_p1p2\", \"ln_p1p3\", \"ln_p2p3\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           intercept      ln_q     ln2_q    ln_qp1    ln_qp2    ln_qp3  \\\n",
      "intercept   8.485895 -0.096160  0.000206  0.015677 -0.022104  0.006427   \n",
      "ln_q       -0.096160  0.016015 -0.000070 -0.002912  0.002270  0.000642   \n",
      "ln2_q       0.000206 -0.000070  0.000020 -0.000016 -0.000002  0.000019   \n",
      "ln_qp1      0.015677 -0.002912 -0.000016  0.000585 -0.000363 -0.000222   \n",
      "ln_qp2     -0.022104  0.002270 -0.000002 -0.000363  0.000654 -0.000291   \n",
      "ln_qp3      0.006427  0.000642  0.000019 -0.000222 -0.000291  0.000513   \n",
      "ln_p1      -3.050502  0.012193 -0.000038 -0.001377  0.005099 -0.003722   \n",
      "ln_p2       1.613544 -0.014739  0.000150  0.001701 -0.006121  0.004419   \n",
      "ln_p3       1.436958  0.002546 -0.000112 -0.000324  0.001022 -0.000697   \n",
      "ln2_p1      0.198259  0.000797  0.000012 -0.000240 -0.000166  0.000406   \n",
      "ln2_p2     -0.045968 -0.001459  0.000031  0.000281  0.000029 -0.000310   \n",
      "ln2_p3     -0.411072 -0.000658 -0.000048  0.000287  0.000230 -0.000517   \n",
      "ln_p1p2    -0.281682  0.000002 -0.000046  0.000123  0.000184 -0.000307   \n",
      "ln_p1p3     0.083423 -0.000799  0.000033  0.000117 -0.000018 -0.000099   \n",
      "ln_p2p3     0.327650  0.001457  0.000015 -0.000404 -0.000213  0.000617   \n",
      "\n",
      "              ln_p1     ln_p2     ln_p3    ln2_p1    ln2_p2    ln2_p3  \\\n",
      "intercept -3.050502  1.613544  1.436958  0.198259 -0.045968 -0.411072   \n",
      "ln_q       0.012193 -0.014739  0.002546  0.000797 -0.001459 -0.000658   \n",
      "ln2_q     -0.000038  0.000150 -0.000112  0.000012  0.000031 -0.000048   \n",
      "ln_qp1    -0.001377  0.001701 -0.000324 -0.000240  0.000281  0.000287   \n",
      "ln_qp2     0.005099 -0.006121  0.001022 -0.000166  0.000029  0.000230   \n",
      "ln_qp3    -0.003722  0.004419 -0.000697  0.000406 -0.000310 -0.000517   \n",
      "ln_p1      1.151568 -0.589638 -0.561930 -0.078231  0.022798  0.154840   \n",
      "ln_p2     -0.589638  0.343127  0.246511  0.039021 -0.001273 -0.085612   \n",
      "ln_p3     -0.561930  0.246511  0.315419  0.039210 -0.021524 -0.069228   \n",
      "ln2_p1    -0.078231  0.039021  0.039210  0.005550 -0.002064 -0.010488   \n",
      "ln2_p2     0.022798 -0.001273 -0.021524 -0.002064  0.007181 -0.001587   \n",
      "ln2_p3     0.154840 -0.085612 -0.069228 -0.010488 -0.001587  0.025193   \n",
      "ln_p1p2    0.105136 -0.061679 -0.043457 -0.006987 -0.003352  0.018634   \n",
      "ln_p1p3   -0.026906  0.022659  0.004247  0.001437  0.005416 -0.008146   \n",
      "ln_p2p3   -0.127934  0.062953  0.064981  0.009051 -0.003828 -0.017047   \n",
      "\n",
      "            ln_p1p2   ln_p1p3   ln_p2p3  \n",
      "intercept -0.281682  0.083423  0.327650  \n",
      "ln_q       0.000002 -0.000799  0.001457  \n",
      "ln2_q     -0.000046  0.000033  0.000015  \n",
      "ln_qp1     0.000123  0.000117 -0.000404  \n",
      "ln_qp2     0.000184 -0.000018 -0.000213  \n",
      "ln_qp3    -0.000307 -0.000099  0.000617  \n",
      "ln_p1      0.105136 -0.026906 -0.127934  \n",
      "ln_p2     -0.061679  0.022659  0.062953  \n",
      "ln_p3     -0.043457  0.004247  0.064981  \n",
      "ln2_p1    -0.006987  0.001437  0.009051  \n",
      "ln2_p2    -0.003352  0.005416 -0.003828  \n",
      "ln2_p3     0.018634 -0.008146 -0.017047  \n",
      "ln_p1p2    0.014487 -0.007500 -0.011135  \n",
      "ln_p1p3   -0.007500  0.006063  0.002084  \n",
      "ln_p2p3   -0.011135  0.002084  0.014963  \n"
     ]
    }
   ],
   "source": [
    "# 2. Get the covariance matrix 洧뎴ar(洧량틙(洧녠洧洧녡))\n",
    "\n",
    "# To calculate the covariance matrix we create the estimation residuals, \n",
    "# then we find the covvar matrix called \"VarCov_rls\":\n",
    "ln_ct_fit = np.dot(X_big, BETAS_rls)\n",
    "e_resid = np.array(ln_ct) - ln_ct_fit\n",
    "\n",
    "sigma2_rls = np.sum(e_resid**2) / (len(data_smpl.index) - (len(BETAS_rls) - len(rr)))\n",
    "\n",
    "D_mat = np.identity(len(BETAS_rls)) - RA_1.dot(RA_2).dot(L)\n",
    "VarCov_rls = sigma2_rls * D_mat.dot(XTX_inv)\n",
    "\n",
    "print(pd.DataFrame(VarCov_rls, \n",
    "                   index = [\"intercept\", \"ln_q\", \"ln2_q\", \"ln_qp1\", \"ln_qp2\", \"ln_qp3\", \"ln_p1\", \n",
    "                                \"ln_p2\", \"ln_p3\", \"ln2_p1\", \"ln2_p2\", \"ln2_p3\", \"ln_p1p2\", \"ln_p1p3\", \"ln_p2p3\"], \n",
    "                   columns = [\"intercept\", \"ln_q\", \"ln2_q\", \"ln_qp1\", \"ln_qp2\", \"ln_qp3\", \"ln_p1\", \n",
    "                                \"ln_p2\", \"ln_p3\", \"ln2_p1\", \"ln2_p2\", \"ln2_p3\", \"ln_p1p2\", \"ln_p1p3\", \"ln_p2p3\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code bellow uncomment the second line to install savReaderWriter library. The `dict_varlabels` has the labels of the columns of rec1.\n",
    "\n",
    "1. Check if CASEID identifies each observation uniquely. **[Hint: Use is_unique method.](https://pandas.pydata.org/docs/reference/api/pandas.Series.is_unique.html)**\n",
    "2. Make the CASEID column the index of your data set. **[Hint: Use set_index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html)**. \n",
    "3. Keep women who are 15-30 years old and live in Urban areas. **[Hint: Use query](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html)**.\n",
    "4. Generate a new column with the month of born. Just use the first three letters.  Use the English names of the months. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas\n",
    "\n",
    "1. Ejecute el c칩digo a continuaci칩n, descomente la segunda l칤nea para instalar la biblioteca savReaderWriter. El dict_varlabels tiene las etiquetas de las columnas de rec1.\n",
    "\n",
    "2. Compruebe si CASEID identifica cada observaci칩n de forma 칰nica. Sugerencia: utilice el m칠todo is_unique.\n",
    "\n",
    "3. Haga que la columna CASEID sea el 칤ndice de su conjunto de datos. Sugerencia: use set_index.\n",
    "\n",
    "4. Mantenga a las mujeres que tengan entre 15 y 30 a침os y vivan en 치reas urbanas. Sugerencia: use la consulta.\n",
    "\n",
    "5. Genera una nueva columna con el mes de nacimiento. Solo usa las tres primeras letras. Usa los nombres en ingl칠s de los meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in c:\\anaconda\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\anaconda\\lib\\site-packages (from pyreadstat) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\anaconda\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# 1. Instalaci칩n preliminar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "!pip install pyreadstat\n",
    "import savReaderWriter as sav\n",
    "rec1 = pd.read_spss( fr\"C:/Users/USER/Documents/GitHub/Diplomado_PUCP/_data/endes/2019/REC0111.sav\" )\n",
    "\n",
    "with sav.SavHeaderReader( fr\"C:/Users/USER/Documents/GitHub/Diplomado_PUCP/_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "\n",
    "dict_varlabels = metadata[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID1': 'A침o',\n",
       " 'HHID': 'Identificaci칩n Cuestionario del Hogar',\n",
       " 'CASEID': 'Identificaci칩n Cuestionario Individual',\n",
       " 'V001': 'Conglomerado',\n",
       " 'V002': 'N칰mero de vivienda',\n",
       " 'V003': 'N칰mero de l칤nea de entrevistada',\n",
       " 'V004': 'Unidad de 치rea final',\n",
       " 'V007': 'A침o de la entrevista',\n",
       " 'V008': 'Fecha de la entrevista, Codificaci칩n centenaria de meses (CMC)',\n",
       " 'V009': 'Mes de nacimiento de la entrevistada',\n",
       " 'V010': 'A침o de nacimiento de la entrevistada',\n",
       " 'V011': 'Fecha de nacimiento, Codificaci칩n centenaria de meses (CMC)',\n",
       " 'V012': 'Edad actual - entrevistada',\n",
       " 'V013': 'Edad actual por grupos de 5 a침os',\n",
       " 'V014': 'Integridad de la informaci칩n para la fecha de nacimiento ',\n",
       " 'V015': 'Resultado entrevista individual',\n",
       " 'V017': 'Inicio del calendario, Codificaci칩n centenaria de mesesl CMC',\n",
       " 'V018': 'Columna del mes de la entrevista',\n",
       " 'V019': 'Duraci칩n del calendario',\n",
       " 'V019A': 'N칰mero de columnas de calendario',\n",
       " 'V020': 'Muestra alguna vez casada',\n",
       " 'V021': 'Unidad de muestreo primario - conglomerado',\n",
       " 'V023': 'Dominio de ejemplo - Departamento',\n",
       " 'V024': 'Regi칩n',\n",
       " 'V025': 'Tipo de lugar de residencia',\n",
       " 'V026': 'El lugar de residencia en el que se entrevist칩 - De Facto',\n",
       " 'V027': 'N칰mero de visitas',\n",
       " 'V028': 'Identificaci칩n del entrevistador',\n",
       " 'V029': 'Identificador del digitador',\n",
       " 'V030': 'Supervisor de campo',\n",
       " 'V031': 'Editor de campo',\n",
       " 'V032': 'Editor de la oficina',\n",
       " 'V033': 'Selecci칩n final del 치rea de probabilidad',\n",
       " 'V034': 'N칰mero de orden del esposo',\n",
       " 'V040': 'Altitud del conglomerado en metros',\n",
       " 'V042': 'Selecci칩n de hogar para hemoglobina',\n",
       " 'V043': 'Selecci칩n para m칩dulo de estatus de mujeres',\n",
       " 'V044': 'Selecci칩n para m칩dulo de violencia domestica',\n",
       " 'V000': 'C칩digo y fase del pa칤s',\n",
       " 'Q105DD': 'Dia de nacimeinto de la entrevistada',\n",
       " 'V101': 'Regi칩n',\n",
       " 'V102': 'Tipo de lugar de residencia',\n",
       " 'V103': 'Lugar de residencia de la infancia',\n",
       " 'V104': 'Cuanto tiempo tiene viviendo continuamente en el lugar de residencia actual',\n",
       " 'V105': 'Tipo de lugar de residencia anteriormente',\n",
       " 'V106': 'Nivel educativo m치s alto',\n",
       " 'V107': 'A침o/grado de educaci칩n m치s alto aprobado',\n",
       " 'V113': 'Fuente principal de abasteciemiento de agua potable que utilizan en su hogar para tomar o beber',\n",
       " 'V115': 'Tiempo para llegar a la fuente de agua',\n",
       " 'V116': 'Tipo de instalaci칩n sanitaria',\n",
       " 'V119': 'En su hogar tiene: electricidad',\n",
       " 'V120': 'En su hogar tiene: radio',\n",
       " 'V121': 'En su hogar tiene: televisi칩n',\n",
       " 'V122': 'En su hogar tiene: refrigerador',\n",
       " 'V123': 'En su hogar tiene: bicicleta',\n",
       " 'V124': 'En su hogar tiene: motocicleta/motocar',\n",
       " 'V125': 'En su hogar tiene: coche/cami칩n',\n",
       " 'V127': 'Material predominante del piso de la vivienda',\n",
       " 'V128': 'Material predominante de las paredes exteriores de la vivienda',\n",
       " 'V129': 'Material predominante del techo de la vivienda',\n",
       " 'V130': 'Religi칩n',\n",
       " 'V131': 'Etnicidad',\n",
       " 'V133': 'Educaci칩n en a침os simples',\n",
       " 'V134': 'El lugar en el que se realiz칩 la entrevista  De-facto',\n",
       " 'V135': 'Residente habitual o visitante',\n",
       " 'V136': 'N칰mero de miembros del hogar',\n",
       " 'V137': 'N칰mero de ni침os de 6 a침os de edad ',\n",
       " 'V138': 'N칰mero de mujeres de 15 a 49 a침os de edad elegibles en el hogar ',\n",
       " 'V139': 'Regi칩n, residencia habitual De-jure',\n",
       " 'V140': 'Tipo de 치rea de residencia De-jure',\n",
       " 'V141': 'Lugar de residencia De-jure',\n",
       " 'V149': 'Logro educativo',\n",
       " 'V150': 'Relaci칩n con el jefe del hogar',\n",
       " 'V151': 'Sexo del Jefe del Hogar',\n",
       " 'V152': 'Edad del jefe del hogar',\n",
       " 'V153': 'En su hogar tiene: tel칠fono',\n",
       " 'AWFACTT': 'Factor todas las mujeres - total',\n",
       " 'AWFACTU': 'Factor todas las mujeres - urbano/rural',\n",
       " 'AWFACTR': 'Factor todas las mujeres - regional',\n",
       " 'AWFACTE': 'Factor todas las mujeres - educaci칩n',\n",
       " 'AWFACTW': 'Factor todas las mujeres - 칤ndice de riqueza',\n",
       " 'V155': 'Alfabetizaci칩n',\n",
       " 'V156': 'Alguna vez particip칩 en un programa de alfabetizaci칩n (no incluyendo la escuela primaria)',\n",
       " 'V157': 'Frecuencia de lectura de un peri칩dico o revista',\n",
       " 'V158': 'Frecuencia de escuchar radio',\n",
       " 'V159': 'Frecuencia de ver televisi칩n',\n",
       " 'V160': 'Ba침o compartido con otros hogares',\n",
       " 'V161': 'Tipo de combustible para cocinar',\n",
       " 'V166': 'Resultados de la prueba del yodo en la sal',\n",
       " 'V167': 'N칰mero de viajes en los 칰ltimos 12 meses',\n",
       " 'V168': 'Afuera m치s de un mes en los 칰ltimos 12 meses',\n",
       " 'ML101': 'Tipo de mosquitero que utilizo para dormir 칰ltima noche',\n",
       " 'QD333_1': 'Alguna dificultad o limitaci칩n permanente para ver, a칰n usando anteojos',\n",
       " 'QD333_2': 'Alguna dificultad o limitaci칩n permanente para oir, a칰n usando aud칤fonos',\n",
       " 'QD333_3': 'Alguna dificultad o limitaci칩n permanente para hablar o comunicarse, a칰n usando la lengua de se침as u otro',\n",
       " 'QD333_4': 'Alguna dificultad o limitaci칩n permanente para moverse o caminar para usar brazos y/o piernas',\n",
       " 'QD333_5': 'Alguna dificultad o limitaci칩n permanente para entender o aprender (concentrarse y recordarse)',\n",
       " 'QD333_6': 'Alguna dificultad o limitaci칩n permanente para relacionarse con los dem치s, por sus pensamientos, sentimientos, emociones o conductas',\n",
       " 'UBIGEO': 'C칩digo de Ubicaci칩n Gegr치fica',\n",
       " 'V022': 'Estratos',\n",
       " 'V005': 'Factor de ponderacion',\n",
       " 'V190': '칈ndice de riqueza',\n",
       " 'V191': 'Factor de puntuaci칩n del 칤ndice de riqueza (5 decimales)',\n",
       " 'mujeres12a49': 'Mujeres de 12 a 49 a침os de edad',\n",
       " 'NCONGLOME': 'N칰mero de Conglomerado (proveniente del marco)'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_varlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID1</th>\n",
       "      <th>HHID</th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>...</th>\n",
       "      <th>QD333_4</th>\n",
       "      <th>QD333_5</th>\n",
       "      <th>QD333_6</th>\n",
       "      <th>UBIGEO</th>\n",
       "      <th>V022</th>\n",
       "      <th>V005</th>\n",
       "      <th>V190</th>\n",
       "      <th>V191</th>\n",
       "      <th>mujeres12a49</th>\n",
       "      <th>NCONGLOME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000100201</td>\n",
       "      <td>000100201  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.234450</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000100201</td>\n",
       "      <td>000100201  3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.234450</td>\n",
       "      <td>Mujeres de 12 a 14 de edad, nunca embarazadas</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000102801</td>\n",
       "      <td>000102801  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.295611</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000102801</td>\n",
       "      <td>000102801  6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Rico</td>\n",
       "      <td>1.295611</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>000104801</td>\n",
       "      <td>000104801  2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>010101</td>\n",
       "      <td>3.0</td>\n",
       "      <td>154803.0</td>\n",
       "      <td>Pobrer</td>\n",
       "      <td>-0.256431</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>7065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325406201</td>\n",
       "      <td>325406201  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El m치s pobre</td>\n",
       "      <td>-1.750187</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38331</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325406301</td>\n",
       "      <td>325406301  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El m치s pobre</td>\n",
       "      <td>-1.676861</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407001</td>\n",
       "      <td>325407001  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>459792.0</td>\n",
       "      <td>El m치s pobre</td>\n",
       "      <td>-1.585333</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407201</td>\n",
       "      <td>325407201  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>459792.0</td>\n",
       "      <td>El m치s pobre</td>\n",
       "      <td>-1.650159</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38334</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>325407401</td>\n",
       "      <td>325407401  2</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>250401</td>\n",
       "      <td>249.0</td>\n",
       "      <td>244995.0</td>\n",
       "      <td>El m치s pobre</td>\n",
       "      <td>-1.644720</td>\n",
       "      <td>Mujeres de 15 a 49 a침os de edad</td>\n",
       "      <td>15783.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38335 rows 칑 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID1             HHID              CASEID    V001  V002  V003  \\\n",
       "0      2019.0        000100201        000100201  2     1.0   2.0   2.0   \n",
       "1      2019.0        000100201        000100201  3     1.0   2.0   3.0   \n",
       "2      2019.0        000102801        000102801  2     1.0  28.0   2.0   \n",
       "3      2019.0        000102801        000102801  6     1.0  28.0   6.0   \n",
       "4      2019.0        000104801        000104801  2     1.0  48.0   2.0   \n",
       "...       ...              ...                 ...     ...   ...   ...   \n",
       "38330  2019.0        325406201        325406201  2  3254.0  62.0   2.0   \n",
       "38331  2019.0        325406301        325406301  2  3254.0  63.0   2.0   \n",
       "38332  2019.0        325407001        325407001  2  3254.0  70.0   2.0   \n",
       "38333  2019.0        325407201        325407201  2  3254.0  72.0   2.0   \n",
       "38334  2019.0        325407401        325407401  2  3254.0  74.0   2.0   \n",
       "\n",
       "         V004    V007    V008  V009  ...  QD333_4  QD333_5  QD333_6  UBIGEO  \\\n",
       "0         1.0  2019.0  1434.0   4.0  ...       No       No       No  010101   \n",
       "1         1.0  2019.0  1434.0   1.0  ...       No       No       No  010101   \n",
       "2         1.0  2019.0  1434.0   6.0  ...       No       No       No  010101   \n",
       "3         1.0  2019.0  1434.0   3.0  ...       No       No       No  010101   \n",
       "4         1.0  2019.0  1434.0   5.0  ...       No       No       No  010101   \n",
       "...       ...     ...     ...   ...  ...      ...      ...      ...     ...   \n",
       "38330  3254.0  2019.0  1440.0  12.0  ...       No       No       No  250401   \n",
       "38331  3254.0  2019.0  1440.0   6.0  ...       No       No       No  250401   \n",
       "38332  3254.0  2019.0  1440.0   7.0  ...       No       No       No  250401   \n",
       "38333  3254.0  2019.0  1440.0  12.0  ...       No       No       No  250401   \n",
       "38334  3254.0  2019.0  1440.0  10.0  ...       No       No       No  250401   \n",
       "\n",
       "        V022      V005          V190      V191  \\\n",
       "0        3.0  154803.0          Rico  1.234450   \n",
       "1        3.0  154803.0          Rico  1.234450   \n",
       "2        3.0  154803.0          Rico  1.295611   \n",
       "3        3.0  154803.0          Rico  1.295611   \n",
       "4        3.0  154803.0        Pobrer -0.256431   \n",
       "...      ...       ...           ...       ...   \n",
       "38330  249.0  244995.0  El m치s pobre -1.750187   \n",
       "38331  249.0  244995.0  El m치s pobre -1.676861   \n",
       "38332  249.0  459792.0  El m치s pobre -1.585333   \n",
       "38333  249.0  459792.0  El m치s pobre -1.650159   \n",
       "38334  249.0  244995.0  El m치s pobre -1.644720   \n",
       "\n",
       "                                        mujeres12a49  NCONGLOME  \n",
       "0                    Mujeres de 15 a 49 a침os de edad     7065.0  \n",
       "1      Mujeres de 12 a 14 de edad, nunca embarazadas     7065.0  \n",
       "2                    Mujeres de 15 a 49 a침os de edad     7065.0  \n",
       "3                    Mujeres de 15 a 49 a침os de edad     7065.0  \n",
       "4                    Mujeres de 15 a 49 a침os de edad     7065.0  \n",
       "...                                              ...        ...  \n",
       "38330                Mujeres de 15 a 49 a침os de edad    15783.0  \n",
       "38331                Mujeres de 15 a 49 a침os de edad    15783.0  \n",
       "38332                Mujeres de 15 a 49 a침os de edad    15783.0  \n",
       "38333                Mujeres de 15 a 49 a침os de edad    15783.0  \n",
       "38334                Mujeres de 15 a 49 a침os de edad    15783.0  \n",
       "\n",
       "[38335 rows x 105 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(rec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_unique' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [56]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mis_unique\u001b[49m(CASEID)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'is_unique' is not defined"
     ]
    }
   ],
   "source": [
    "is_unique(CASEID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Check if CASEID identifies each observation uniquely. Hint: Use is_unique method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Make the CASEID column the index of your data set. Hint: Use set_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Keep women who are 15-30 years old and live in Urban areas. Hint: Use query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Generate a new column with the month of born. Just use the first three letters. \n",
    "# Use the English names of the months."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
