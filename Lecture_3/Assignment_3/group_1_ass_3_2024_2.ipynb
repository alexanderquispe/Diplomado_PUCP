{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group_1\n",
    "- MAX LENIN CHIPANI LIMA (9 & 10)\n",
    "- ANDRES ALEXANDER VILLACORTA BARRERA (3&4)\n",
    "- ESTEFANNY MIRIAN GIL MAMANI (7&8)\n",
    "- VANESSA ALESSANDRA AZAÑEDO GAMARRAamarena (1&2)\n",
    "- JOSE MARIA MIGUEL LOYOLA ROMERO (5&6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyreadstat in d:\\anaconda\\envs\\diplomado\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas>=1.2.0 in d:\\anaconda\\envs\\diplomado\\lib\\site-packages (from pyreadstat) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in d:\\anaconda\\envs\\diplomado\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\max lenin\\appdata\\roaming\\python\\python311\\site-packages (from pandas>=1.2.0->pyreadstat) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\envs\\diplomado\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\envs\\diplomado\\lib\\site-packages (from pandas>=1.2.0->pyreadstat) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\max lenin\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->pyreadstat) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyreadstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import pyreadstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1\n",
    "\n",
    "## Define the file paths. \n",
    "file_path_1 = \"../../_data/endes/2019/REC0111.sav\"\n",
    "file_path_2 = \"../../_data/endes/2019/RE223132.sav\"\n",
    "file_path_3 = \"../../_data/endes/2019/RE516171.sav\"\n",
    "\n",
    "## Load the .sav files. Use pyreadstat.read_sav instead of pandas.read_spss as it allows to access the metadata; for instance, the variable and value labels.\n",
    "rec_1, meta1 = pyreadstat.read_sav(file_path_1)\n",
    "rec_2, meta2 = pyreadstat.read_sav(file_path_2)\n",
    "rec_3, meta3 = pyreadstat.read_sav(file_path_3)\n",
    "\n",
    "## Extract variable and value labels. \n",
    "var_labels1 = meta1.column_labels\n",
    "value_labels1 = meta1.variable_value_labels\n",
    "\n",
    "var_labels2 = meta2.column_labels\n",
    "value_labels2 = meta2.variable_value_labels\n",
    "\n",
    "var_labels3 = meta3.column_labels\n",
    "value_labels3 = meta3.variable_value_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set. Check if all the columns are in the dataset. Make a code that check the columns that are not included. Please, reporte them.\n",
    "\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns are present in rec_1.\n",
      "All columns are present in rec_2.\n",
      "All columns are present in rec_3.\n"
     ]
    }
   ],
   "source": [
    "import pyreadstat\n",
    "\n",
    "# Define the file paths\n",
    "file_path_1 = \"../../_data/endes/2019/REC0111.sav\"\n",
    "file_path_2 = \"../../_data/endes/2019/RE223132.sav\"\n",
    "file_path_3 = \"../../_data/endes/2019/RE516171.sav\"\n",
    "\n",
    "# Load the .sav files along with their metadata\n",
    "rec_1, meta1 = pyreadstat.read_sav(file_path_1)\n",
    "rec_2, meta2 = pyreadstat.read_sav(file_path_2)\n",
    "rec_3, meta3 = pyreadstat.read_sav(file_path_3)\n",
    "\n",
    "# Define the columns to select for each dataset\n",
    "columns_1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', \n",
    "             'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', \n",
    "             'V124', 'V125', 'V127', 'V133']\n",
    "\n",
    "columns_2 = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', \n",
    "             'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', \n",
    "             'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "\n",
    "columns_3 = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', \n",
    "             'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "\n",
    "# Function to check and report missing columns, and filter the DataFrame using loc\n",
    "def check_and_filter_columns(dataset, metadata, column_list, dataset_name):\n",
    "    missing_columns = [col for col in column_list if col not in dataset.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"The following columns are missing from {dataset_name}: {missing_columns}\")\n",
    "    else:\n",
    "        print(f\"All columns are present in {dataset_name}.\")\n",
    "    \n",
    "    # Filter the DataFrame using .loc to include only the selected columns\n",
    "    selected_columns = [col for col in column_list if col in dataset.columns]\n",
    "    filtered_data = dataset.loc[:, selected_columns]\n",
    "\n",
    "    # Check if column_labels and variable_value_labels are dictionaries\n",
    "    if isinstance(metadata.column_labels, dict):\n",
    "        filtered_var_labels = {k: metadata.column_labels[k] for k in selected_columns}\n",
    "    else:\n",
    "        filtered_var_labels = {k: metadata.column_labels[metadata.column_names.index(k)] for k in selected_columns}\n",
    "\n",
    "    if isinstance(metadata.variable_value_labels, dict):\n",
    "        filtered_value_labels = {k: metadata.variable_value_labels[k] for k in selected_columns if k in metadata.variable_value_labels}\n",
    "    else:\n",
    "        filtered_value_labels = {k: metadata.variable_value_labels[metadata.column_names.index(k)] for k in selected_columns if k in metadata.variable_value_labels}\n",
    "    \n",
    "    return filtered_data, filtered_var_labels, filtered_value_labels\n",
    "\n",
    "# Apply the function to each dataset\n",
    "rec1_1, new_var_labels1, new_value_labels1 = check_and_filter_columns(rec_1, meta1, columns_1, 'rec_1')\n",
    "rec2_1, new_var_labels2, new_value_labels2 = check_and_filter_columns(rec_2, meta2, columns_2, 'rec_2')\n",
    "rec3_1, new_var_labels3, new_value_labels3 = check_and_filter_columns(rec_3, meta3, columns_3, 'rec_3')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V102</th>\n",
       "      <th>V120</th>\n",
       "      <th>V121</th>\n",
       "      <th>V122</th>\n",
       "      <th>V123</th>\n",
       "      <th>V124</th>\n",
       "      <th>V125</th>\n",
       "      <th>V127</th>\n",
       "      <th>V133</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100201  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>325406201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38331</th>\n",
       "      <td>325406301  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>325407001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>325407201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38334</th>\n",
       "      <td>325407401  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38335 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CASEID V000    V001  V002  V003    V004    V007    V008  \\\n",
       "0            000100201  2  PE6     1.0   2.0   2.0     1.0  2019.0  1434.0   \n",
       "1            000100201  3  PE6     1.0   2.0   3.0     1.0  2019.0  1434.0   \n",
       "2            000102801  2  PE6     1.0  28.0   2.0     1.0  2019.0  1434.0   \n",
       "3            000102801  6  PE6     1.0  28.0   6.0     1.0  2019.0  1434.0   \n",
       "4            000104801  2  PE6     1.0  48.0   2.0     1.0  2019.0  1434.0   \n",
       "...                   ...  ...     ...   ...   ...     ...     ...     ...   \n",
       "38330        325406201  2  PE6  3254.0  62.0   2.0  3254.0  2019.0  1440.0   \n",
       "38331        325406301  2  PE6  3254.0  63.0   2.0  3254.0  2019.0  1440.0   \n",
       "38332        325407001  2  PE6  3254.0  70.0   2.0  3254.0  2019.0  1440.0   \n",
       "38333        325407201  2  PE6  3254.0  72.0   2.0  3254.0  2019.0  1440.0   \n",
       "38334        325407401  2  PE6  3254.0  74.0   2.0  3254.0  2019.0  1440.0   \n",
       "\n",
       "       V009    V010  ...  V102  V120  V121  V122  V123  V124  V125  V127  \\\n",
       "0       4.0  1986.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0   \n",
       "1       1.0  2007.0  ...   1.0   1.0   1.0   1.0   0.0   0.0   0.0  33.0   \n",
       "2       6.0  1983.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0   \n",
       "3       3.0  1970.0  ...   1.0   1.0   1.0   1.0   1.0   1.0   1.0  33.0   \n",
       "4       5.0  1991.0  ...   1.0   0.0   0.0   0.0   0.0   0.0   0.0  34.0   \n",
       "...     ...     ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "38330  12.0  1971.0  ...   2.0   0.0   0.0   0.0   0.0   0.0   0.0  96.0   \n",
       "38331   6.0  1988.0  ...   2.0   0.0   0.0   0.0   0.0   0.0   0.0  96.0   \n",
       "38332   7.0  1973.0  ...   2.0   0.0   0.0   0.0   0.0   0.0   0.0  96.0   \n",
       "38333  12.0  1994.0  ...   2.0   0.0   0.0   0.0   0.0   0.0   0.0  96.0   \n",
       "38334  10.0  1996.0  ...   2.0   0.0   0.0   0.0   0.0   0.0   0.0  96.0   \n",
       "\n",
       "       V133  year  \n",
       "0      16.0  2019  \n",
       "1       6.0  2019  \n",
       "2      16.0  2019  \n",
       "3       4.0  2019  \n",
       "4       1.0  2019  \n",
       "...     ...   ...  \n",
       "38330   4.0  2019  \n",
       "38331   6.0  2019  \n",
       "38332   3.0  2019  \n",
       "38333   9.0  2019  \n",
       "38334   9.0  2019  \n",
       "\n",
       "[38335 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the new column\n",
    "rec1_1.loc[:,\"year\"]=\"2019\"\n",
    "rec1_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We udpate the new variable\n",
    "new_var_labels1.update({'year':\"Year of the survey\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(rec1_1, rec2_1, on='CASEID', how='outer')\n",
    "endes_2019 = pd.merge(merged_df, rec3_1, on='CASEID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CASEID V000  V001  V002  V003  V004    V007    V008  V009  \\\n",
      "0        000100201  2  PE6   1.0   2.0   2.0   1.0  2019.0  1434.0   4.0   \n",
      "1        000100201  3  PE6   1.0   2.0   3.0   1.0  2019.0  1434.0   1.0   \n",
      "2        000102801  2  PE6   1.0  28.0   2.0   1.0  2019.0  1434.0   6.0   \n",
      "3        000102801  6  PE6   1.0  28.0   6.0   1.0  2019.0  1434.0   3.0   \n",
      "4        000104801  2  PE6   1.0  48.0   2.0   1.0  2019.0  1434.0   5.0   \n",
      "\n",
      "     V010  ...    V508    V509  V510  V511  V512  V513  V525  V613  V714  V715  \n",
      "0  1986.0  ...  2008.0  1297.0   1.0  21.0  11.0   3.0  17.0   2.0   1.0  11.0  \n",
      "1  2007.0  ...     NaN     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
      "2  1983.0  ...  2011.0  1344.0   1.0  28.0   7.0   2.0  18.0   3.0   1.0  14.0  \n",
      "3  1970.0  ...  1984.0  1016.0   5.0  14.0  34.0   7.0  14.0   0.0   0.0   6.0  \n",
      "4  1991.0  ...  2009.0  1320.0   1.0  18.0   9.0   2.0  15.0   2.0   0.0   6.0  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "print(endes_2019.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V007</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>...</th>\n",
       "      <th>V508</th>\n",
       "      <th>V509</th>\n",
       "      <th>V510</th>\n",
       "      <th>V511</th>\n",
       "      <th>V512</th>\n",
       "      <th>V513</th>\n",
       "      <th>V525</th>\n",
       "      <th>V613</th>\n",
       "      <th>V714</th>\n",
       "      <th>V715</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000100201  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38330</th>\n",
       "      <td>325406201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38331</th>\n",
       "      <td>325406301  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>1236.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38332</th>\n",
       "      <td>325407001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1043.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38333</th>\n",
       "      <td>325407201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1301.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38334</th>\n",
       "      <td>325407401  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3254.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38335 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   CASEID V000    V001  V002  V003    V004    V007    V008  \\\n",
       "0            000100201  2  PE6     1.0   2.0   2.0     1.0  2019.0  1434.0   \n",
       "1            000100201  3  PE6     1.0   2.0   3.0     1.0  2019.0  1434.0   \n",
       "2            000102801  2  PE6     1.0  28.0   2.0     1.0  2019.0  1434.0   \n",
       "3            000102801  6  PE6     1.0  28.0   6.0     1.0  2019.0  1434.0   \n",
       "4            000104801  2  PE6     1.0  48.0   2.0     1.0  2019.0  1434.0   \n",
       "...                   ...  ...     ...   ...   ...     ...     ...     ...   \n",
       "38330        325406201  2  PE6  3254.0  62.0   2.0  3254.0  2019.0  1440.0   \n",
       "38331        325406301  2  PE6  3254.0  63.0   2.0  3254.0  2019.0  1440.0   \n",
       "38332        325407001  2  PE6  3254.0  70.0   2.0  3254.0  2019.0  1440.0   \n",
       "38333        325407201  2  PE6  3254.0  72.0   2.0  3254.0  2019.0  1440.0   \n",
       "38334        325407401  2  PE6  3254.0  74.0   2.0  3254.0  2019.0  1440.0   \n",
       "\n",
       "       V009    V010  ...    V508    V509  V510  V511  V512  V513  V525  V613  \\\n",
       "0       4.0  1986.0  ...  2008.0  1297.0   1.0  21.0  11.0   3.0  17.0   2.0   \n",
       "1       1.0  2007.0  ...     NaN     NaN   NaN   NaN   NaN   NaN   NaN   NaN   \n",
       "2       6.0  1983.0  ...  2011.0  1344.0   1.0  28.0   7.0   2.0  18.0   3.0   \n",
       "3       3.0  1970.0  ...  1984.0  1016.0   5.0  14.0  34.0   7.0  14.0   0.0   \n",
       "4       5.0  1991.0  ...  2009.0  1320.0   1.0  18.0   9.0   2.0  15.0   2.0   \n",
       "...     ...     ...  ...     ...     ...   ...   ...   ...   ...   ...   ...   \n",
       "38330  12.0  1971.0  ...  1985.0  1032.0   1.0  14.0  34.0   7.0  12.0   3.0   \n",
       "38331   6.0  1988.0  ...  2002.0  1236.0   1.0  14.0  17.0   4.0  12.0   3.0   \n",
       "38332   7.0  1973.0  ...  1986.0  1043.0   1.0  13.0  33.0   7.0  12.0   4.0   \n",
       "38333  12.0  1994.0  ...  2008.0  1301.0   1.0  13.0  11.0   3.0  13.0   2.0   \n",
       "38334  10.0  1996.0  ...  2013.0  1362.0   1.0  16.0   6.0   2.0  15.0   2.0   \n",
       "\n",
       "       V714  V715  \n",
       "0       1.0  11.0  \n",
       "1       NaN   NaN  \n",
       "2       1.0  14.0  \n",
       "3       0.0   6.0  \n",
       "4       0.0   6.0  \n",
       "...     ...   ...  \n",
       "38330   0.0   5.0  \n",
       "38331   0.0   7.0  \n",
       "38332   0.0   5.0  \n",
       "38333   0.0  11.0  \n",
       "38334   0.0  11.0  \n",
       "\n",
       "[38335 rows x 64 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We merge requested dataframes in one\n",
    "endes_2019=rec1_1.merge(rec2_1,on='CASEID',how='outer')\\\n",
    "                .merge(rec3_1,on='CASEID',how='outer')\n",
    "endes_2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We unify the variables \n",
    "var_labels = new_var_labels1.copy()\n",
    "var_labels.update(new_var_labels2)\n",
    "var_labels.update(new_var_labels3)\n",
    "\n",
    "# We unify the values\n",
    "value_labels = new_value_labels1.copy()\n",
    "value_labels.update(new_value_labels2)\n",
    "value_labels.update(new_value_labels3)\n",
    "\n",
    "# We generate new attributes for endes_2019\n",
    "endes_2019.attrs['var_labels'] = var_labels\n",
    "endes_2019.attrs['value_labels'] = value_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyreadstat\n",
    "\n",
    "# Define the base path to the data files and the years to process\n",
    "base_path = \"../../_data/endes/\"\n",
    "years = [2019, 2018, 2017, 2016, 2015]\n",
    "file_names = [\"REC0111.sav\", \"RE223132.sav\", \"RE516171.sav\"]\n",
    "\n",
    "# Initialize the dictionary to store all data\n",
    "all_data = {}\n",
    "\n",
    "# Loop through each year\n",
    "for year in years:\n",
    "    try:\n",
    "        # Initialize a dictionary for the current year\n",
    "        year_data = {}\n",
    "        \n",
    "        # Initialize lists to store the DataFrames and combined labels\n",
    "        data_frames = []\n",
    "        var_labels = {}\n",
    "        value_labels = {}\n",
    "\n",
    "        # Loop through each file\n",
    "        for file_name in file_names:\n",
    "            # Construct the full path to the file\n",
    "            file_path = os.path.join(base_path, str(year), file_name)\n",
    "            \n",
    "            # Read the .sav file and capture the data along with the labels\n",
    "            data, meta = pyreadstat.read_sav(file_path)\n",
    "            \n",
    "            # Update the variable and value labels\n",
    "            var_labels.update(meta.column_names_to_labels)\n",
    "            value_labels.update(meta.variable_value_labels)\n",
    "            \n",
    "            # Filter the common columns you want to keep (adjust according to your needs)\n",
    "            if file_name == \"REC0111.sav\":\n",
    "                selected_columns = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "            elif file_name == \"RE223132.sav\":\n",
    "                selected_columns = ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']\n",
    "            elif file_name == \"RE516171.sav\":\n",
    "                selected_columns = ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']\n",
    "            \n",
    "            # Filter the selected columns\n",
    "            filtered_data = data[selected_columns]\n",
    "            \n",
    "            # Add the filtered DataFrame to the list\n",
    "            data_frames.append(filtered_data)\n",
    "        \n",
    "        # Add the year column to the first DataFrame\n",
    "        data_frames[0]['year'] = year\n",
    "        \n",
    "        # Merge the DataFrames using 'CASEID'\n",
    "        combined_data = data_frames[0]\n",
    "        for df in data_frames[1:]:\n",
    "            combined_data = combined_data.merge(df, on='CASEID', how='inner')\n",
    "        \n",
    "        # Store the data and labels in the dictionary for the current year\n",
    "        year_data['data'] = combined_data\n",
    "        year_data['var_labels'] = var_labels\n",
    "        year_data['value_labels'] = value_labels\n",
    "        \n",
    "        # Add the current year's data to the main dictionary\n",
    "        all_data[f'year_{year}'] = year_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing files for year {year}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estefanny Gil\n",
    "# Initialize a list to store all dataFrames\n",
    "dataframes_list = []\n",
    "\n",
    "# Loop through the all_data dictionary to extract DataFrames\n",
    "for year_key, year_data in all_data.items():\n",
    "    # Append the DataFrame for the current year to the list\n",
    "    dataframes_list.append(year_data['data'])\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "endes_data_2015_2019 = pd.concat(dataframes_list, axis=0, ignore_index=True)\n",
    "\n",
    "# Reset the index to have a clean DataFrame\n",
    "endes_data_2015_2019.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>V011</th>\n",
       "      <th>...</th>\n",
       "      <th>V508</th>\n",
       "      <th>V509</th>\n",
       "      <th>V510</th>\n",
       "      <th>V511</th>\n",
       "      <th>V512</th>\n",
       "      <th>V513</th>\n",
       "      <th>V525</th>\n",
       "      <th>V613</th>\n",
       "      <th>V714</th>\n",
       "      <th>V715</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000100201  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>1036.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000102801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000102801  6</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>843.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1016.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1097.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000113601  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>1067.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170371</th>\n",
       "      <td>317503501  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>1303.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170372</th>\n",
       "      <td>317503701  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>852.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170373</th>\n",
       "      <td>317507601  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170374</th>\n",
       "      <td>317507801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1204.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170375</th>\n",
       "      <td>317508001  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>1389.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>170376 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    CASEID V000    V001   V002  V003    V004    V008  V009  \\\n",
       "0             000100201  2  PE6     1.0    2.0   2.0     1.0  1434.0   4.0   \n",
       "1             000102801  2  PE6     1.0   28.0   2.0     1.0  1434.0   6.0   \n",
       "2             000102801  6  PE6     1.0   28.0   6.0     1.0  1434.0   3.0   \n",
       "3             000104801  2  PE6     1.0   48.0   2.0     1.0  1434.0   5.0   \n",
       "4             000113601  2  PE6     1.0  136.0   2.0     1.0  1434.0  11.0   \n",
       "...                    ...  ...     ...    ...   ...     ...     ...   ...   \n",
       "170371        317503501  2  PE6  3175.0   35.0   2.0  3175.0  1389.0   1.0   \n",
       "170372        317503701  2  PE6  3175.0   37.0   2.0  3175.0  1389.0  12.0   \n",
       "170373        317507601  1  PE6  3175.0   76.0   1.0  3175.0  1389.0  10.0   \n",
       "170374        317507801  2  PE6  3175.0   78.0   2.0  3175.0  1389.0   4.0   \n",
       "170375        317508001  2  PE6  3175.0   80.0   2.0  3175.0  1389.0   7.0   \n",
       "\n",
       "          V010    V011  ...    V508    V509  V510  V511  V512  V513  V525  \\\n",
       "0       1986.0  1036.0  ...  2008.0  1297.0   1.0  21.0  11.0   3.0  17.0   \n",
       "1       1983.0  1002.0  ...  2011.0  1344.0   1.0  28.0   7.0   2.0  18.0   \n",
       "2       1970.0   843.0  ...  1984.0  1016.0   5.0  14.0  34.0   7.0  14.0   \n",
       "3       1991.0  1097.0  ...  2009.0  1320.0   1.0  18.0   9.0   2.0  15.0   \n",
       "4       1988.0  1067.0  ...  2005.0  1272.0   1.0  17.0  13.0   3.0  15.0   \n",
       "...        ...     ...  ...     ...     ...   ...   ...   ...   ...   ...   \n",
       "170371  1989.0  1069.0  ...  2008.0  1303.0   1.0  19.0   7.0   2.0  15.0   \n",
       "170372  1970.0   852.0  ...  1991.0  1098.0   1.0  20.0  24.0   5.0  14.0   \n",
       "170373  1972.0   874.0  ...  1993.0  1118.0   1.0  20.0  22.0   5.0  12.0   \n",
       "170374  2000.0  1204.0  ...     NaN     NaN   NaN   NaN   NaN   0.0   0.0   \n",
       "170375  1984.0  1015.0  ...  2004.0  1250.0   1.0  19.0  11.0   3.0  18.0   \n",
       "\n",
       "        V613  V714  V715  \n",
       "0        2.0   1.0  11.0  \n",
       "1        3.0   1.0  14.0  \n",
       "2        0.0   0.0   6.0  \n",
       "3        2.0   0.0   6.0  \n",
       "4        2.0   1.0  16.0  \n",
       "...      ...   ...   ...  \n",
       "170371   1.0   1.0  11.0  \n",
       "170372   3.0   1.0   0.0  \n",
       "170373   3.0   1.0   3.0  \n",
       "170374   2.0   0.0   NaN  \n",
       "170375   2.0   0.0  11.0  \n",
       "\n",
       "[170376 rows x 63 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endes_data_2015_2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2019.,   nan])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endes_data_2015_2019['ID1'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`.  **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estefanny Gil\n",
    "all_var_labels = {}\n",
    "all_value_labels = {}\n",
    "\n",
    "# Loop through the all_data dictionary to extract var_labels and value_labels\n",
    "for year_key, year_data in all_data.items():\n",
    "    # Extract year from the key (e.g., 'year_2019' -> 2019)\n",
    "    year = int(year_key.split('_')[1])\n",
    "    \n",
    "    # Store var_labels and value_labels in dictionaries\n",
    "    all_var_labels[year] = year_data['var_labels']\n",
    "    all_value_labels[year] = year_data['value_labels']\n",
    "\n",
    "# Combine all var_labels and value_labels\n",
    "combined_var_labels = {}\n",
    "combined_value_labels = {}\n",
    "\n",
    "# Populate combined labels (assuming all labels should be included for the full dataset)\n",
    "for year, var_labels in all_var_labels.items():\n",
    "    combined_var_labels.update(var_labels)\n",
    "for year, value_labels in all_value_labels.items():\n",
    "    combined_value_labels.update(value_labels)\n",
    "\n",
    "# Create a dictionary to store the labels with column names\n",
    "var_labels_dict = {col: combined_var_labels.get(col, 'No label') for col in endes_data_2015_2019.columns}\n",
    "value_labels_dict = {col: combined_value_labels.get(col, 'No value label') for col in endes_data_2015_2019.columns}\n",
    "\n",
    "# Add the labels to the DataFrame as attributes (not as columns)\n",
    "endes_data_2015_2019.attrs['var_labels'] = var_labels_dict\n",
    "endes_data_2015_2019.attrs['value_labels'] = value_labels_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    CASEID V000    V001   V002  V003    V004    V008  V009  \\\n",
      "0             000100201  2  PE6     1.0    2.0   2.0     1.0  1434.0   4.0   \n",
      "1             000102801  2  PE6     1.0   28.0   2.0     1.0  1434.0   6.0   \n",
      "2             000102801  6  PE6     1.0   28.0   6.0     1.0  1434.0   3.0   \n",
      "3             000104801  2  PE6     1.0   48.0   2.0     1.0  1434.0   5.0   \n",
      "4             000113601  2  PE6     1.0  136.0   2.0     1.0  1434.0  11.0   \n",
      "...                    ...  ...     ...    ...   ...     ...     ...   ...   \n",
      "170371        317503501  2  PE6  3175.0   35.0   2.0  3175.0  1389.0   1.0   \n",
      "170372        317503701  2  PE6  3175.0   37.0   2.0  3175.0  1389.0  12.0   \n",
      "170373        317507601  1  PE6  3175.0   76.0   1.0  3175.0  1389.0  10.0   \n",
      "170374        317507801  2  PE6  3175.0   78.0   2.0  3175.0  1389.0   4.0   \n",
      "170375        317508001  2  PE6  3175.0   80.0   2.0  3175.0  1389.0   7.0   \n",
      "\n",
      "          V010    V011  ...    V508    V509  V510  V511  V512  V513  V525  \\\n",
      "0       1986.0  1036.0  ...  2008.0  1297.0   1.0  21.0  11.0   3.0  17.0   \n",
      "1       1983.0  1002.0  ...  2011.0  1344.0   1.0  28.0   7.0   2.0  18.0   \n",
      "2       1970.0   843.0  ...  1984.0  1016.0   5.0  14.0  34.0   7.0  14.0   \n",
      "3       1991.0  1097.0  ...  2009.0  1320.0   1.0  18.0   9.0   2.0  15.0   \n",
      "4       1988.0  1067.0  ...  2005.0  1272.0   1.0  17.0  13.0   3.0  15.0   \n",
      "...        ...     ...  ...     ...     ...   ...   ...   ...   ...   ...   \n",
      "170371  1989.0  1069.0  ...  2008.0  1303.0   1.0  19.0   7.0   2.0  15.0   \n",
      "170372  1970.0   852.0  ...  1991.0  1098.0   1.0  20.0  24.0   5.0  14.0   \n",
      "170373  1972.0   874.0  ...  1993.0  1118.0   1.0  20.0  22.0   5.0  12.0   \n",
      "170374  2000.0  1204.0  ...     NaN     NaN   NaN   NaN   NaN   0.0   0.0   \n",
      "170375  1984.0  1015.0  ...  2004.0  1250.0   1.0  19.0  11.0   3.0  18.0   \n",
      "\n",
      "        V613  V714  V715  \n",
      "0        2.0   1.0  11.0  \n",
      "1        3.0   1.0  14.0  \n",
      "2        0.0   0.0   6.0  \n",
      "3        2.0   0.0   6.0  \n",
      "4        2.0   1.0  16.0  \n",
      "...      ...   ...   ...  \n",
      "170371   1.0   1.0  11.0  \n",
      "170372   3.0   1.0   0.0  \n",
      "170373   3.0   1.0   3.0  \n",
      "170374   2.0   0.0   NaN  \n",
      "170375   2.0   0.0  11.0  \n",
      "\n",
      "[170376 rows x 63 columns]\n"
     ]
    }
   ],
   "source": [
    "print(endes_data_2015_2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>V024</th>\n",
       "      <th>mean_total_children</th>\n",
       "      <th>mean_ideal_children</th>\n",
       "      <th>mean_hb_yr_educ</th>\n",
       "      <th>mean_first_marriage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.028594</td>\n",
       "      <td>2.608964</td>\n",
       "      <td>11.469806</td>\n",
       "      <td>20.587935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.415771</td>\n",
       "      <td>2.389785</td>\n",
       "      <td>9.792669</td>\n",
       "      <td>19.641466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.711661</td>\n",
       "      <td>2.190895</td>\n",
       "      <td>10.816594</td>\n",
       "      <td>22.038043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.493585</td>\n",
       "      <td>2.550979</td>\n",
       "      <td>9.655594</td>\n",
       "      <td>20.037555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2019</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.977733</td>\n",
       "      <td>2.119433</td>\n",
       "      <td>11.174870</td>\n",
       "      <td>20.398964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2019</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.100392</td>\n",
       "      <td>2.493333</td>\n",
       "      <td>9.705545</td>\n",
       "      <td>18.953155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2019</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.544563</td>\n",
       "      <td>2.013083</td>\n",
       "      <td>12.815937</td>\n",
       "      <td>22.065095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2019</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.938121</td>\n",
       "      <td>2.469824</td>\n",
       "      <td>11.856468</td>\n",
       "      <td>19.409821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2019</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.290015</td>\n",
       "      <td>2.388399</td>\n",
       "      <td>10.788566</td>\n",
       "      <td>18.985481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  V024  mean_total_children  mean_ideal_children  mean_hb_yr_educ  \\\n",
       "0    2015   1.0             2.445515             3.041512         8.602355   \n",
       "1    2015   2.0             2.028594             2.608964        11.469806   \n",
       "2    2015   3.0             2.415771             2.389785         9.792669   \n",
       "3    2015   4.0             1.711661             2.190895        10.816594   \n",
       "4    2015   5.0             2.493585             2.550979         9.655594   \n",
       "..    ...   ...                  ...                  ...              ...   \n",
       "120  2019  21.0             1.977733             2.119433        11.174870   \n",
       "121  2019  22.0             2.100392             2.493333         9.705545   \n",
       "122  2019  23.0             1.544563             2.013083        12.815937   \n",
       "123  2019  24.0             1.938121             2.469824        11.856468   \n",
       "124  2019  25.0             2.290015             2.388399        10.788566   \n",
       "\n",
       "     mean_first_marriage  \n",
       "0              19.014493  \n",
       "1              20.587935  \n",
       "2              19.641466  \n",
       "3              22.038043  \n",
       "4              20.037555  \n",
       "..                   ...  \n",
       "120            20.398964  \n",
       "121            18.953155  \n",
       "122            22.065095  \n",
       "123            19.409821  \n",
       "124            18.985481  \n",
       "\n",
       "[125 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group the data by year and department, and calculate the mean for specified columns\n",
    "mean_key_vars = endes_data_2015_2019.groupby(['year', 'V024']).agg(\n",
    "    mean_total_children=pd.NamedAgg(column='V201', aggfunc='mean'),\n",
    "    mean_ideal_children=pd.NamedAgg(column='V613', aggfunc='mean'),\n",
    "    mean_hb_yr_educ=pd.NamedAgg(column='V715', aggfunc='mean'),\n",
    "    mean_first_marriage=pd.NamedAgg(column='V511', aggfunc='mean')\n",
    ").reset_index()\n",
    "\n",
    "# Display the rows of the result\n",
    "mean_key_vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASEID</th>\n",
       "      <th>V000</th>\n",
       "      <th>V001</th>\n",
       "      <th>V002</th>\n",
       "      <th>V003</th>\n",
       "      <th>V004</th>\n",
       "      <th>V008</th>\n",
       "      <th>V009</th>\n",
       "      <th>V010</th>\n",
       "      <th>V011</th>\n",
       "      <th>...</th>\n",
       "      <th>V512</th>\n",
       "      <th>V513</th>\n",
       "      <th>V525</th>\n",
       "      <th>V613</th>\n",
       "      <th>V714</th>\n",
       "      <th>V715</th>\n",
       "      <th>mean_total_children</th>\n",
       "      <th>mean_ideal_children</th>\n",
       "      <th>mean_hb_yr_educ</th>\n",
       "      <th>mean_first_marriage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000102701  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000104301  1</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000104801  2</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000104801  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1999.0</td>\n",
       "      <td>1199.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000105001  3</td>\n",
       "      <td>PE6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.445515</td>\n",
       "      <td>3.041512</td>\n",
       "      <td>8.602355</td>\n",
       "      <td>19.014493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               CASEID V000  V001  V002  V003  V004    V008  V009    V010  \\\n",
       "0        000102701  1  PE6   1.0  27.0   1.0   1.0  1386.0   7.0  1985.0   \n",
       "1        000104301  1  PE6   1.0  43.0   1.0   1.0  1386.0   4.0  1974.0   \n",
       "2        000104801  2  PE6   1.0  48.0   2.0   1.0  1386.0   1.0  1980.0   \n",
       "3        000104801  3  PE6   1.0  48.0   3.0   1.0  1386.0  11.0  1999.0   \n",
       "4        000105001  3  PE6   1.0  50.0   3.0   1.0  1386.0   8.0  1993.0   \n",
       "\n",
       "     V011  ...  V512  V513  V525  V613  V714  V715  mean_total_children  \\\n",
       "0  1027.0  ...  13.0   3.0  15.0   4.0   1.0   3.0             2.445515   \n",
       "1   892.0  ...   8.0   2.0  26.0   2.0   0.0   9.0             2.445515   \n",
       "2   961.0  ...  17.0   4.0  18.0   1.0   1.0  11.0             2.445515   \n",
       "3  1199.0  ...   NaN   0.0   0.0   0.0   1.0   NaN             2.445515   \n",
       "4  1124.0  ...   NaN   0.0  21.0   2.0   0.0   NaN             2.445515   \n",
       "\n",
       "   mean_ideal_children  mean_hb_yr_educ  mean_first_marriage  \n",
       "0             3.041512         8.602355            19.014493  \n",
       "1             3.041512         8.602355            19.014493  \n",
       "2             3.041512         8.602355            19.014493  \n",
       "3             3.041512         8.602355            19.014493  \n",
       "4             3.041512         8.602355            19.014493  \n",
       "\n",
       "[5 rows x 67 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We merge the dataframes.\n",
    "final_result = endes_data_2015_2019.merge(mean_key_vars, on=['year', 'V024'], how='right') \n",
    "\n",
    "final_result.head() "
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
