{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import savReaderWriter as sav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read REC0111 data\n",
    "rec1 = pd.read_spss( fr\"../../_data/endes/2019/REC0111.sav\" )\n",
    "\n",
    "# Get labels from sav file\n",
    "with sav.SavHeaderReader( fr\"../../_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    \n",
    "# variables labels\n",
    "var_labels1 = metadata.varLabels.copy()\n",
    "# Values labels\n",
    "value_labels1 = metadata.valueLabels.copy()\n",
    "\n",
    "# read RE223132 data\n",
    "rec2 = pd.read_spss( fr\"../../_data/endes/2019/RE223132.sav\" )\n",
    "\n",
    "# Get labels from sav file\n",
    "with sav.SavHeaderReader( fr\"../../_data/endes/2019/RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    \n",
    "# variables labels\n",
    "var_labels2 = metadata.varLabels.copy()\n",
    "# Values labels\n",
    "value_labels2 = metadata.valueLabels.copy()\n",
    "\n",
    "# read RE516171 data    \n",
    "rec3 = pd.read_spss( fr\"../../_data/endes/2019/RE516171.sav\" )\n",
    "\n",
    "# Get labels from sav file\n",
    "with sav.SavHeaderReader( fr\"../../_data/endes/2019/RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    \n",
    "# variables labels\n",
    "var_labels3 = metadata.varLabels.copy()\n",
    "# Values labels\n",
    "value_labels3 = metadata.valueLabels.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additioanlly, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter, `for loop`,   and [this link](https://stackoverflow.com/questions/3420122/filter-dict-to-contain-only-certain-keys) to update the var and value dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = ['CASEID', 'V000', 'V001', 'V002', 'V003', 'V004', 'V007', 'V008', 'V009', 'V010', 'V011', 'V012', 'V024', 'V102', 'V120', 'V121', 'V122', 'V123', 'V124', 'V125', 'V127', 'V133']\n",
    "col2 = [ 'CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380' ]\n",
    "col3 = [ 'CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering col1\n",
    "\n",
    "rec1_1 = rec1.loc[ : , col1 ]\n",
    "\n",
    "# variables kyes\n",
    "var_labels_keys = var_labels1.keys()\n",
    "# Values keys\n",
    "value_labels_keys = value_labels1.keys()\n",
    "\n",
    "# Filtered variables\n",
    "new_var_labels1 = {}\n",
    "new_value_labels1 = {}\n",
    "# New variable and value labels\n",
    "for key in col1:\n",
    "\n",
    "    if key in var_labels_keys:\n",
    "        new_var_labels1[ f'{key}' ] = var_labels1[ f'{key}' ]\n",
    "\n",
    "    if key in value_labels_keys:\n",
    "        new_value_labels1[ f'{key}' ] = value_labels1[ f'{key}' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Specific Ccol2\n",
    "rec2_1 = rec2.loc[ : ,col2 ]\n",
    "\n",
    "# variables kyes\n",
    "var_labels_keys = var_labels2.keys()\n",
    "# Values keys\n",
    "value_labels_keys = value_labels2.keys()\n",
    "\n",
    "# Filtered variables\n",
    "new_var_labels2 = {}\n",
    "new_value_labels2 = {}\n",
    "# New variable and value labels\n",
    "for key in col2:\n",
    "\n",
    "    if key in var_labels_keys:\n",
    "        new_var_labels2[ f'{key}' ] = var_labels2[ f'{key}' ]\n",
    "\n",
    "    if key in value_labels_keys:\n",
    "        new_value_labels2[ f'{key}' ] = value_labels2[ f'{key}' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col3\n",
    "# V001-V012\n",
    "# Filter col3\n",
    "rec3_1 = rec3.loc[ : , col3 ].copy()\n",
    "\n",
    "\n",
    "# variables kyes\n",
    "var_labels_keys = var_labels3.keys()\n",
    "# Values keys\n",
    "value_labels_keys = value_labels3.keys()\n",
    "\n",
    "\n",
    "# Filtered variables\n",
    "new_var_labels3 = {}\n",
    "new_value_labels3 = {}\n",
    "# New variable and value labels\n",
    "for key in col3:\n",
    "\n",
    "    if key in var_labels_keys:\n",
    "        new_var_labels3[ f'{key}' ] = var_labels3[ f'{key}' ]\n",
    "\n",
    "    if key in value_labels_keys:\n",
    "        new_value_labels3[ f'{key}' ] = value_labels3[ f'{key}' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1_1['year'] = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_labels1['year'] = \"Year of the survey\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019 = rec1_1.merge( \n",
    "            rec2_1, \n",
    "            on = 'CASEID', \n",
    "            how = 'outer', \n",
    "            validate = \"1:1\" \n",
    "          ).merge( \n",
    "                rec3_1, \n",
    "                on = 'CASEID', \n",
    "                how = 'outer', \n",
    "                validate = \"1:1\" \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. Your final output should be equal to `endes_2019_ta` object **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_var_labels1.update( new_var_labels2 )\n",
    "new_var_labels1.update( new_var_labels3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_value_labels1.update( new_value_labels2 )\n",
    "new_value_labels1.update( new_value_labels3 )\n",
    "\n",
    "var_labels = new_var_labels1.copy()\n",
    "value_labels = new_value_labels1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_2019.attrs[ 'var_labels' ] = var_labels\n",
    "endes_2019.attrs[ 'value_labels' ] = value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open( r'../../_data/endes_2019_ta.pkl' , \"wb\")\n",
    "pickle.dump( endes_2019, file_to_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open(r'../../_data/endes_2019_ta.pkl', 'rb')\n",
    "endes_2019_ta = pickle.load( output )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now, replicate your code of the prevoius sections but for years **2019, 2018, 2017, 2016, 2015**. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their **variables and values labels** from this path `\"../../_data/endes/\"`. For this excersie you must use a for loop. This loop must iterate over **2019, 2018, 2017, 2016, 2015 folders** and import these files. All the files have the same name. You must store these files and their labels in a nested dictionary named as `all_data`. The keys of the dictionary should be named as `year_2019`, for example, and the keys of the nested dictionary should be `data`, `var_labels`, and `value_labels`. The output of this exercise should be equal to the `all_data_ta` object. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "all_data_ta = {}\n",
    "for year in range( 2015, 2020 ):\n",
    "    print(f\"{year}\")\n",
    "    \n",
    "    # read REC0111 data\n",
    "    endes1 = pd.read_spss( fr\"../../_data/endes/{year}/REC0111.sav\" )\n",
    "\n",
    "    # Get labels from sav file\n",
    "    with sav.SavHeaderReader( fr\"../../_data/endes/{year}/REC0111.sav\", ioUtf8=True) as header:\n",
    "        metadata = header.all()\n",
    "\n",
    "    # Filtering columns\n",
    "    # new pandas with selected columns\n",
    "    endes1_1 = endes1.loc[ : , col1 ]\n",
    "    # generate the year column\n",
    "    endes1_1[ 'year' ] = year\n",
    "\n",
    "    # variables labels\n",
    "    var_labels = metadata.varLabels.copy()\n",
    "    # variables kyes\n",
    "    var_labels_keys = var_labels.keys()\n",
    "    # Values labels\n",
    "    value_labels = metadata.valueLabels.copy()\n",
    "    # Values keys\n",
    "    value_labels_keys = value_labels.keys()\n",
    "\n",
    "    # Filtered variables\n",
    "    new_var_labels1 = {}\n",
    "    new_value_labels1 = {}\n",
    "    # New variable and value labels\n",
    "    for key in columns:\n",
    "\n",
    "        if key in var_labels_keys:\n",
    "            new_var_labels1[ f'{key}' ] = var_labels[ f'{key}' ]\n",
    "\n",
    "        if key in value_labels_keys:\n",
    "            new_value_labels1[ f'{key}' ] = value_labels[ f'{key}' ]\n",
    "    \n",
    "    # update Year of the survey to the dictionary\n",
    "    new_var_labels1['year'] = \"Year of the survey\"\n",
    "    \n",
    "            \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    # read RE223132 data\n",
    "    endes2 = pd.read_spss( fr\"../../_data/endes/{year}/RE223132.sav\" )\n",
    "\n",
    "    # Get labels from sav file\n",
    "    with sav.SavHeaderReader( fr\"../../_data/endes/{year}/RE223132.sav\", ioUtf8=True) as header:\n",
    "        metadata = header.all()\n",
    "    \n",
    "    # Selecting Specific Columns\n",
    "    endes2_1 = endes2.loc[ : ,col2 ]\n",
    "    \n",
    "    # variables labels\n",
    "    var_labels = metadata.varLabels.copy()\n",
    "    # variables kyes\n",
    "    var_labels_keys = var_labels.keys()\n",
    "    # Values labels\n",
    "    value_labels = metadata.valueLabels.copy()\n",
    "    # Values keys\n",
    "    value_labels_keys = value_labels.keys()\n",
    "\n",
    "    # Filtered variables\n",
    "    new_var_labels2 = {}\n",
    "    new_value_labels2 = {}\n",
    "    # New variable and value labels\n",
    "    for key in columns:\n",
    "\n",
    "        if key in var_labels_keys:\n",
    "            new_var_labels2[ f'{key}' ] = var_labels[ f'{key}' ]\n",
    "\n",
    "        if key in value_labels_keys:\n",
    "            new_value_labels2[ f'{key}' ] = value_labels[ f'{key}' ]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # read RE516171 data    \n",
    "    endes3 = pd.read_spss( fr\"../../_data/endes/{year}/RE516171.sav\" )\n",
    "\n",
    "    # Get labels from sav file\n",
    "    with sav.SavHeaderReader( fr\"../../_data/endes/{year}/RE516171.sav\", ioUtf8=True) as header:\n",
    "        metadata = header.all()\n",
    "\n",
    "    # Filter columns\n",
    "    endes3_1 = endes3.loc[ : , col3 ].copy()\n",
    "\n",
    "    # variables labels\n",
    "    var_labels = metadata.varLabels.copy()\n",
    "    # variables kyes\n",
    "    var_labels_keys = var_labels.keys()\n",
    "    # Values labels\n",
    "    value_labels = metadata.valueLabels.copy()\n",
    "    # Values keys\n",
    "    value_labels_keys = value_labels.keys()\n",
    "\n",
    "    # Filtered variables\n",
    "    new_var_labels3 = {}\n",
    "    new_value_labels3 = {}\n",
    "    # New variable and value labels\n",
    "    for key in columns:\n",
    "\n",
    "        if key in var_labels_keys:\n",
    "            new_var_labels3[ f'{key}' ] = var_labels[ f'{key}' ]\n",
    "\n",
    "        if key in value_labels_keys:\n",
    "            new_value_labels3[ f'{key}' ] = value_labels[ f'{key}' ]\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Merging data\n",
    "    endes = endes1_1.merge( \n",
    "                endes2_1, \n",
    "                on = 'CASEID', \n",
    "                how = 'left', \n",
    "                validate = \"1:1\" \n",
    "              ).merge( \n",
    "                    endes3_1, \n",
    "                    on = 'CASEID', \n",
    "                    how = 'left', \n",
    "                    validate = \"1:1\" \n",
    "                    )\n",
    "    \n",
    "    # Concatenate all var labels\n",
    "    new_var_labels1.update( new_var_labels2 )\n",
    "    new_var_labels1.update( new_var_labels3 )\n",
    "    var_labels = new_var_labels1.copy()\n",
    "\n",
    "    # Concatenate all value labels\n",
    "    new_value_labels1.update( new_value_labels2 )\n",
    "    new_value_labels1.update( new_value_labels3 )\n",
    "    value_labels = new_value_labels1.copy()\n",
    "    \n",
    "    # Store all values\n",
    "    store_values = {\"data\" : endes , \n",
    "                      \"var_labels\" : var_labels, \n",
    "                      \"value_labels\" : value_labels\n",
    "                    }\n",
    "    all_data_ta[ f'year_{year}'] = store_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open( r'../../_data/all_data_ta.pkl' , \"wb\")\n",
    "pickle.dump( all_data_ta, file_to_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `all_data` to append all the data sets. Store all data sets in a list using `for loop`. Then, use `pd.concat` to append all the data sets. Also, you must reset the index to have a good-looking data. This new object should be named as `endes_data_2015_2019`. **Hint: Use [this code](https://stackoverflow.com/questions/32444138/concatenate-a-list-of-pandas-dataframes-together)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'var_labels', 'value_labels'])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_ta['year_2015'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_ta = []\n",
    "for year in range( 2015, 2020 ):\n",
    "    data = all_results[ f'year_{year}' ]['data']\n",
    "    all_data.append( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019_ta = pd.concat( all_data ).reset_index( drop = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Store all the `var_labels` and `value_labels` in a dictionary named as `all_var_labels` and `all_value_labels`. The first keys should be the year for both dictionaries.Then, use them to generate new attributes for `endes_data_2015_2019`. These attributes should be named as `var_labels` and `value_labels`. Your final output should be equal to `endes_data_2015_2019_ta` object. **Hint: Use [this link](https://notebooks.githubusercontent.com/view/ipynb?browser=chrome&color_mode=auto&commit=4d6de78e00e7001f16bf6473c2eb7ce24fb611cd&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f616c6578616e6465727175697370652f4469706c6f6d61646f5f505543502f346436646537386530306537303031663136626636343733633265623763653234666236313163642f4c6563747572655f342f4c6563747572655f342e6970796e62&logged_in=true&nwo=alexanderquispe%2FDiplomado_PUCP&path=Lecture_4%2FLecture_4.ipynb&platform=windows&repository_id=427747212&repository_type=Repository&version=95#4.2.3.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_labels = {}\n",
    "value_labels = {}\n",
    "for year in range( 2015, 2020 ):\n",
    "    var_labels[ f'{ year }' ] = all_data_ta[ f'year_{year}' ]['var_labels']\n",
    "    value_labels[ f'{ year }' ] = all_data_ta[ f'year_{year}' ]['value_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019_ta.attrs[ 'var_labels' ] = var_labels\n",
    "endes_data_2015_2019_ta.attrs[ 'value_labels' ] = value_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open( r'../../_data/endes_data_2015_2019_ta.pkl' , \"wb\")\n",
    "pickle.dump( endes_data_2015_2019_ta, file_to_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Use `endes_data_2015_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019_ta.V613.replace( \n",
    "                        ('Non-numeric response', 'Respuesta no num√©rica'), \n",
    "                        (np.nan, np.nan), \n",
    "                        inplace = True \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "endes_data_2015_2019_ta.V715.replace( \n",
    "                        (\"Don't know\", 'No sabe'), \n",
    "                        (np.nan, np.nan), \n",
    "                        inplace = True \n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_key_vars = endes_data_2015_2019_ta.groupby( \n",
    "                [ 'year' ,'V024'], \n",
    "                as_index = False \n",
    "            ).agg( \n",
    "                mean_total_children = ( \"V201\" , np.mean), \n",
    "                mean_ideal_children = ( \"V613\" , np.mean), \n",
    "                mean_hb_yr_educ = ( \"V715\" , np.mean), \n",
    "                mean_first_marriage = ( \"V511\" , np.mean), \n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `mean_key_vars` with `endes_data_2015_2019`. Name this object `final_result`. Your ouput should be equal to `final_result_ta`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result_ta = endes_data_2015_2019_ta.merge( mean1 , on = [ 'year' ,'V024'] , validate = \"m:1\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_store = open( r'../../_data/final_result_ta.pkl' , \"wb\")\n",
    "pickle.dump( final_result_ta, file_to_store)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
